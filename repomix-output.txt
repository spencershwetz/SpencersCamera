This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-12-23T16:54:07.237Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
camera/
  Assets.xcassets/
    AccentColor.colorset/
      Contents.json
    AppIcon.appiconset/
      Contents.json
    Contents.json
  camera.xcdatamodeld/
    camera.xcdatamodel/
      contents
    .xccurrentversion
  Features/
    Camera/
      CameraError.swift
      CameraPreviewView.swift
      CameraViewModel.swift
    Settings/
      SettingsModel.swift
      SettingsView.swift
  Preview Content/
    Preview Assets.xcassets/
      Contents.json
  cameraApp.swift
  ContentView.swift
  Info.plist
  Persistence.swift
camera.xcodeproj/
  project.xcworkspace/
    contents.xcworkspacedata
  xcuserdata/
    spencer.xcuserdatad/
      xcschemes/
        xcschememanagement.plist
  project.pbxproj

================================================================
Repository Files
================================================================

================
File: camera/Assets.xcassets/AccentColor.colorset/Contents.json
================
{
  "colors" : [
    {
      "idiom" : "universal"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: camera/Assets.xcassets/AppIcon.appiconset/Contents.json
================
{
  "images" : [
    {
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    },
    {
      "appearances" : [
        {
          "appearance" : "luminosity",
          "value" : "dark"
        }
      ],
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    },
    {
      "appearances" : [
        {
          "appearance" : "luminosity",
          "value" : "tinted"
        }
      ],
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: camera/Assets.xcassets/Contents.json
================
{
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: camera/camera.xcdatamodeld/camera.xcdatamodel/contents
================
<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<model type="com.apple.IDECoreDataModeler.DataModel" documentVersion="1.0" lastSavedToolsVersion="1" systemVersion="11A491" minimumToolsVersion="Automatic" sourceLanguage="Swift" usedWithCloudKit="false" userDefinedModelVersionIdentifier="">
    <entity name="Item" representedClassName="Item" syncable="YES" codeGenerationType="class">
        <attribute name="timestamp" optional="YES" attributeType="Date" usesScalarValueType="NO"/>
    </entity>
    <elements>
        <element name="Item" positionX="-63" positionY="-18" width="128" height="44"/>
    </elements>
</model>

================
File: camera/camera.xcdatamodeld/.xccurrentversion
================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>_XCCurrentVersionName</key>
	<string>camera.xcdatamodel</string>
</dict>
</plist>

================
File: camera/Features/Camera/CameraError.swift
================
import Foundation

enum CameraError: Error, Identifiable {
    case cameraUnavailable
    case setupFailed
    case configurationFailed
    case recordingFailed
    case savingFailed
    
    var id: String { description }
    
    var description: String {
        switch self {
        case .cameraUnavailable:
            return "Camera device not available"
        case .setupFailed:
            return "Failed to setup camera"
        case .configurationFailed:
            return "Failed to configure camera settings"
        case .recordingFailed:
            return "Failed to record video"
        case .savingFailed:
            return "Failed to save video to photo library"
        }
    }
}

================
File: camera/Features/Camera/CameraPreviewView.swift
================
import SwiftUI
import AVFoundation

struct CameraPreviewView: UIViewRepresentable {
    let session: AVCaptureSession
    
    class PreviewView: UIView {
        override class var layerClass: AnyClass {
            AVCaptureVideoPreviewLayer.self
        }
        
        var videoPreviewLayer: AVCaptureVideoPreviewLayer {
            return layer as! AVCaptureVideoPreviewLayer
        }
    }
    
    func makeUIView(context: Context) -> PreviewView {
        let view = PreviewView()
        view.videoPreviewLayer.session = session
        view.videoPreviewLayer.videoGravity = .resizeAspect
        
        // Initial orientation setup
        updatePreviewLayerOrientation(view.videoPreviewLayer)
        
        // Add orientation change observer
        NotificationCenter.default.addObserver(
            forName: UIDevice.orientationDidChangeNotification,
            object: nil,
            queue: .main) { _ in
                updatePreviewLayerOrientation(view.videoPreviewLayer)
            }
        
        return view
    }
    
    func updateUIView(_ uiView: PreviewView, context: Context) {
        CATransaction.begin()
        CATransaction.setAnimationDuration(0.25)
        updatePreviewLayerOrientation(uiView.videoPreviewLayer)
        CATransaction.commit()
    }
    
    private func updatePreviewLayerOrientation(_ layer: AVCaptureVideoPreviewLayer) {
        guard let connection = layer.connection else { return }
        
        let currentDevice = UIDevice.current
        let orientation = currentDevice.orientation
        
        if #available(iOS 17.0, *) {
            switch orientation {
            case .portrait:
                connection.videoRotationAngle = 90
            case .landscapeRight: // Device rotated left
                connection.videoRotationAngle = 180
            case .landscapeLeft: // Device rotated right
                connection.videoRotationAngle = 0
            case .portraitUpsideDown:
                connection.videoRotationAngle = 270
            default:
                connection.videoRotationAngle = 90
            }
        } else {
            switch orientation {
            case .portrait:
                connection.videoOrientation = .portrait
            case .landscapeRight: // Device rotated left
                connection.videoOrientation = .landscapeLeft
            case .landscapeLeft: // Device rotated right
                connection.videoOrientation = .landscapeRight
            case .portraitUpsideDown:
                connection.videoOrientation = .portraitUpsideDown
            default:
                connection.videoOrientation = .portrait
            }
        }
    }
}

================
File: camera/Features/Camera/CameraViewModel.swift
================
import AVFoundation
import SwiftUI
import Photos
import VideoToolbox
import CoreVideo

class CameraViewModel: NSObject, ObservableObject {
    @Published var isSessionRunning = false
    @Published var error: CameraError?
    @Published var whiteBalance: Float = 5000 // Kelvin
    @Published var iso: Float = 100
    @Published var shutterSpeed: CMTime = CMTimeMake(value: 1, timescale: 60) // 1/60
    @Published var isRecording = false
    @Published var recordingFinished = false
    @Published var isSettingsPresented = false
    @Published var isProcessingRecording = false
    @Published var isAppleLogEnabled: Bool = false {
        didSet {
            handleAppleLogSettingChanged()
        }
    }
    @Published var isAppleLogSupported: Bool = false
    
    let session = AVCaptureSession()
    private var device: AVCaptureDevice?
    private var videoOutput: AVCaptureVideoDataOutput?
    private var audioOutput: AVCaptureAudioDataOutput?
    private var assetWriter: AVAssetWriter?
    private var videoInput: AVAssetWriterInput?
    private var audioInput: AVAssetWriterInput?
    private var currentRecordingURL: URL?
    private let settingsModel = SettingsModel()
    private let videoOutputQueue = DispatchQueue(label: "com.camera.videoOutput")
    private let audioOutputQueue = DispatchQueue(label: "com.camera.audioOutput")
    
    var minISO: Float {
        device?.activeFormat.minISO ?? 50
    }
    
    var maxISO: Float {
        device?.activeFormat.maxISO ?? 1600
    }
    
    override init() {
        super.init()
        print("\n=== Camera Initialization ===")
        setupSession()
        
        // Check if device supports Apple Log
        if let device = device {
            print("📊 Device Capabilities:")
            print("- Name: \(device.localizedName)")
            print("- Model ID: \(device.modelID)")
            
            print("\n🎨 Supported Color Spaces:")
            device.formats.forEach { format in
                let dimensions = CMVideoFormatDescriptionGetDimensions(format.formatDescription)
                let codecType = CMFormatDescriptionGetMediaSubType(format.formatDescription)
                print("""
                    Format: \(dimensions.width)x\(dimensions.height) - Codec: \(codecType)
                    - Color Spaces: \(format.supportedColorSpaces.map { $0.rawValue })
                    - Supports Apple Log: \(format.supportedColorSpaces.contains(.appleLog))
                    - Supports HDR: \(format.isVideoHDRSupported)
                    """)
            }
            
            isAppleLogSupported = device.formats.contains { format in
                format.supportedColorSpaces.contains(.appleLog)
            }
            print("\n✅ Apple Log Support: \(isAppleLogSupported)")
        }
        print("=== End Initialization ===\n")
    }
    
    private func findBestAppleLogFormat(_ device: AVCaptureDevice) -> AVCaptureDevice.Format? {
        return device.formats.first { format in
            let desc = format.formatDescription
            let dimensions = CMVideoFormatDescriptionGetDimensions(desc)
            let codecType = CMFormatDescriptionGetMediaSubType(desc)
            
            // Look for 4K ProRes format with Apple Log support
            let is4K = (dimensions.width == 3840 && dimensions.height == 2160)
            let isProRes = (codecType == 2016686642) // x422 codec
            let hasAppleLog = format.supportedColorSpaces.contains(.appleLog)
            let hasHDR = format.isVideoHDRSupported
            
            return is4K && isProRes && hasAppleLog && hasHDR
        }
    }
    
    private func handleAppleLogSettingChanged() {
        guard let device = device else {
            print("❌ No camera device available")
            return
        }
        
        print("\n=== Apple Log State Change ===")
        print("🎥 Current device: \(device.localizedName)")
        print("📊 Current format: \(device.activeFormat.formatDescription)")
        print("🎨 Current color space: \(device.activeColorSpace.rawValue)")
        print("🔄 Changing to: \(isAppleLogEnabled ? "Apple Log" : "sRGB")")
        
        do {
            session.stopRunning()
            print("⏸️ Session stopped for reconfiguration")
            
            DispatchQueue.main.async {
                self.isSessionRunning = false
            }
            
            Thread.sleep(forTimeInterval: 0.1)
            session.beginConfiguration()
            
            if isAppleLogEnabled {
                if let format = findBestAppleLogFormat(device) {
                    let frameRateRange = format.videoSupportedFrameRateRanges.first!
                    print("⚙️ Setting frame rate: \(frameRateRange.minFrameRate)-\(frameRateRange.maxFrameRate) fps")
                    
                    try device.lockForConfiguration()
                    device.activeVideoMinFrameDuration = CMTime(value: 1, timescale: Int32(frameRateRange.maxFrameRate))
                    device.activeVideoMaxFrameDuration = CMTime(value: 1, timescale: Int32(frameRateRange.minFrameRate))
                    device.activeFormat = format
                    device.activeColorSpace = .appleLog
                    device.unlockForConfiguration()
                    
                    print("✅ Successfully enabled Apple Log")
                    print("📹 New format: \(format.formatDescription)")
                } else {
                    print("⚠️ No suitable Apple Log format found")
                }
            } else {
                try device.lockForConfiguration()
                device.activeColorSpace = .sRGB
                device.unlockForConfiguration()
                print("✅ Reset to sRGB color space")
            }
            
            session.commitConfiguration()
            print("💾 Configuration committed")
            
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                self?.session.startRunning()
                print("▶️ Session restarted")
                
                DispatchQueue.main.async {
                    self?.isSessionRunning = self?.session.isRunning ?? false
                    print("📱 UI updated - session running: \(self?.session.isRunning ?? false)")
                }
            }
            
        } catch {
            print("❌ Error updating Apple Log setting: \(error.localizedDescription)")
            self.error = .configurationFailed
            
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                self?.session.startRunning()
                print("🔄 Attempting session recovery")
            }
        }
        
        print("=== End Apple Log State Change ===\n")
    }
    
    private func setupSession() {
        session.beginConfiguration()
        
        // Configure camera input
        guard let videoDevice = AVCaptureDevice.default(.builtInWideAngleCamera,
                                                      for: .video,
                                                      position: .back) else {
            error = .cameraUnavailable
            session.commitConfiguration()
            return
        }
        
        self.device = videoDevice
        
        do {
            // Configure initial format based on Apple Log settings
            if isAppleLogEnabled && isAppleLogSupported {
                if let appleLogFormat = findBestAppleLogFormat(videoDevice) {
                    // Set frame rate before changing format
                    let frameRateRange = appleLogFormat.videoSupportedFrameRateRanges.first!
                    try videoDevice.lockForConfiguration()
                    videoDevice.activeVideoMinFrameDuration = CMTime(value: 1, timescale: Int32(frameRateRange.maxFrameRate))
                    videoDevice.activeVideoMaxFrameDuration = CMTime(value: 1, timescale: Int32(frameRateRange.minFrameRate))
                    
                    // Set format and color space
                    videoDevice.activeFormat = appleLogFormat
                    videoDevice.activeColorSpace = .appleLog
                    videoDevice.unlockForConfiguration()
                    print("Initial setup: Enabled Apple Log in 4K ProRes format")
                }
            }
            
            let videoInput = try AVCaptureDeviceInput(device: videoDevice)
            
            if session.canAddInput(videoInput) {
                session.addInput(videoInput)
            }
            
            // Rest of setup (audio, video output, etc.)
            // ... existing code ...
            
        } catch {
            print("Error setting up camera: \(error)")
            self.error = .setupFailed
            session.commitConfiguration()
            return
        }
        
        session.commitConfiguration()
        
        // Start the session
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            self?.session.startRunning()
            
            DispatchQueue.main.async {
                self?.isSessionRunning = self?.session.isRunning ?? false
            }
        }
    }
    
    private func setupVideoOutput() -> AVCaptureVideoDataOutput {
        let videoOutput = AVCaptureVideoDataOutput()
        videoOutput.setSampleBufferDelegate(self, queue: videoOutputQueue)
        
        // Configure video output format for Apple Log
        if isAppleLogEnabled && isAppleLogSupported {
            // First check available formats
            let availableFormats = videoOutput.availableVideoPixelFormatTypes
            print("Available video pixel formats: \(availableFormats)")
            
            // Try to find a suitable 10-bit format
            let preferredFormats: [OSType] = [
                kCVPixelFormatType_422YpCbCr10,
                kCVPixelFormatType_420YpCbCr10BiPlanarVideoRange,
                kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange  // Fallback
            ]
            
            let format = preferredFormats.first { availableFormats.contains($0) }
            
            guard let pixelFormat = format else {
                print("No suitable pixel format found for Apple Log")
                // Fall back to standard format
                let settings: [String: Any] = [
                    kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange,
                    kCVPixelBufferMetalCompatibilityKey as String: true
                ]
                videoOutput.videoSettings = settings
                return videoOutput
            }
            
            let videoSettings: [String: Any] = [
                kCVPixelBufferPixelFormatTypeKey as String: pixelFormat,
                kCVPixelBufferMetalCompatibilityKey as String: true
            ]
            videoOutput.videoSettings = videoSettings
            print("Configured video output for Apple Log with format: \(pixelFormat)")
        } else {
            let videoSettings: [String: Any] = [
                kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange,
                kCVPixelBufferMetalCompatibilityKey as String: true
            ]
            videoOutput.videoSettings = videoSettings
            print("Configured video output for standard recording")
        }
        
        videoOutput.alwaysDiscardsLateVideoFrames = false
        return videoOutput
    }
    
    func updateWhiteBalance(_ temperature: Float) {
        guard let device = device else { return }
        
        do {
            try device.lockForConfiguration()
            let temperatureAndTint = AVCaptureDevice.WhiteBalanceTemperatureAndTintValues(temperature: temperature, tint: 0.0)
            var gains = device.deviceWhiteBalanceGains(for: temperatureAndTint)
            let maxGain = device.maxWhiteBalanceGain
            
            gains.redGain   = min(gains.redGain,   maxGain)
            gains.greenGain = min(gains.greenGain, maxGain)
            gains.blueGain  = min(gains.blueGain,  maxGain)
            gains.redGain   = max(1.0, gains.redGain)
            gains.greenGain = max(1.0, gains.greenGain)
            gains.blueGain  = max(1.0, gains.blueGain)
            
            device.setWhiteBalanceModeLocked(with: gains) { _ in }
            device.unlockForConfiguration()
            
            whiteBalance = temperature
        } catch {
            print("White balance error: \(error)")
            self.error = .configurationFailed
        }
    }
    
    func updateISO(_ iso: Float) {
        guard let device = device else { return }
        
        do {
            try device.lockForConfiguration()
            let clampedISO = min(max(device.activeFormat.minISO, iso), device.activeFormat.maxISO)
            device.setExposureModeCustom(duration: device.exposureDuration, iso: clampedISO) { _ in }
            device.unlockForConfiguration()
            self.iso = clampedISO
        } catch {
            print("ISO error: \(error)")
            self.error = .configurationFailed
        }
    }
    
    func updateShutterSpeed(_ speed: CMTime) {
        guard let device = device else { return }
        
        do {
            try device.lockForConfiguration()
            device.setExposureModeCustom(duration: speed, iso: device.iso) { _ in }
            device.unlockForConfiguration()
            
            shutterSpeed = speed
        } catch {
            self.error = .configurationFailed
        }
    }
    
    func startRecording() {
        guard !isRecording && !isProcessingRecording else {
            print("Cannot start recording: Already in progress or processing")
            return
        }
        
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let videoPath = documentsPath.appendingPathComponent("recording-\(Date().timeIntervalSince1970).mov")
        currentRecordingURL = videoPath
        
        do {
            assetWriter = try AVAssetWriter(url: videoPath, fileType: .mov)
            
            // ProRes with Apple Log
            var videoSettings: [String: Any] = [
                AVVideoCodecKey: AVVideoCodecType.proRes422,
                AVVideoWidthKey: NSNumber(value: 3840),
                AVVideoHeightKey: NSNumber(value: 2160)
            ]
            
            if isAppleLogEnabled && isAppleLogSupported {
                videoSettings[AVVideoColorPropertiesKey] = [
                    AVVideoColorPrimariesKey: AVVideoColorPrimaries_ITU_R_2020,
                    AVVideoTransferFunctionKey: AVVideoTransferFunction_ITU_R_2100_HLG,
                    AVVideoYCbCrMatrixKey: AVVideoYCbCrMatrix_ITU_R_2020
                ]
                print("Configuring 4K ProRes with Apple Log")
            }
            
            // Create video input with format hint
            if let currentFormat = device?.activeFormat {
                videoInput = AVAssetWriterInput(mediaType: .video,
                                              outputSettings: videoSettings,
                                              sourceFormatHint: currentFormat.formatDescription)
            } else {
                videoInput = AVAssetWriterInput(mediaType: .video,
                                              outputSettings: videoSettings)
            }
            
            videoInput?.expectsMediaDataInRealTime = true
            
            if let videoInput = videoInput,
               assetWriter?.canAdd(videoInput) == true {
                assetWriter?.add(videoInput)
            }
            
            // Audio
            let audioSettings: [String: Any] = [
                AVFormatIDKey: kAudioFormatMPEG4AAC,
                AVSampleRateKey: 48000,
                AVNumberOfChannelsKey: 2,
                AVEncoderBitRateKey: 256_000
            ]
            
            audioInput = AVAssetWriterInput(mediaType: .audio, outputSettings: audioSettings)
            audioInput?.expectsMediaDataInRealTime = true
            
            if let audioInput = audioInput,
               assetWriter?.canAdd(audioInput) == true {
                assetWriter?.add(audioInput)
            }
            
            isRecording = true
            print("Starting 4K ProRes recording to: \(videoPath)")
            
        } catch {
            print("Failed to create asset writer: \(error)")
            self.error = .recordingFailed
        }
    }
    
    func stopRecording() {
        guard isRecording else {
            print("Cannot stop recording: No ongoing recording")
            return
        }
        
        print("Stopping recording...")
        isProcessingRecording = true
        isRecording = false
        
        // Check asset writer status before finishing
        guard let writer = assetWriter,
              writer.status == .writing else {
            print("❌ Cannot stop recording: Asset writer status is \(assetWriter?.status.rawValue ?? -1)")
            isProcessingRecording = false
            error = .recordingFailed
            return
        }
        
        // Use a dispatch group to ensure both inputs are finished
        let finishGroup = DispatchGroup()
        
        if let videoInput = videoInput {
            finishGroup.enter()
            videoOutputQueue.async {
                videoInput.markAsFinished()
                finishGroup.leave()
            }
        }
        
        if let audioInput = audioInput {
            finishGroup.enter()
            audioOutputQueue.async {
                audioInput.markAsFinished()
                finishGroup.leave()
            }
        }
        
        finishGroup.notify(queue: .main) { [weak self] in
            guard let self = self else { return }
            print("Finishing asset writer...")
            
            writer.finishWriting { [weak self] in
                guard let self = self else { return }
                
                if let error = writer.error {
                    print("❌ Error finishing recording: \(error)")
                    DispatchQueue.main.async {
                        self.error = .recordingFailed
                        self.isProcessingRecording = false
                    }
                    return
                }
                
                if let outputURL = self.currentRecordingURL {
                    print("✅ Recording finished successfully")
                    self.saveVideoToPhotoLibrary(outputURL)
                } else {
                    print("❌ No output URL available")
                    DispatchQueue.main.async {
                        self.error = .recordingFailed
                        self.isProcessingRecording = false
                    }
                }
            }
        }
    }
    
    private func saveVideoToPhotoLibrary(_ outputURL: URL) {
        PHPhotoLibrary.requestAuthorization { [weak self] status in
            guard status == .authorized else {
                DispatchQueue.main.async {
                    self?.error = .savingFailed
                    self?.isProcessingRecording = false
                    print("Photo library access denied")
                }
                return
            }
            
            PHPhotoLibrary.shared().performChanges {
                let options = PHAssetResourceCreationOptions()
                options.shouldMoveFile = true
                let creationRequest = PHAssetCreationRequest.forAsset()
                creationRequest.addResource(with: .video, fileURL: outputURL, options: options)
            } completionHandler: { success, error in
                DispatchQueue.main.async {
                    if success {
                        print("ProRes video saved to photo library")
                        self?.recordingFinished = true
                    } else {
                        print("Error saving video: \(String(describing: error))")
                        self?.error = .savingFailed
                    }
                    self?.isProcessingRecording = false
                }
            }
        }
    }
}

// MARK: - Sample Buffer Delegate
extension CameraViewModel: AVCaptureVideoDataOutputSampleBufferDelegate, AVCaptureAudioDataOutputSampleBufferDelegate {
    func captureOutput(_ output: AVCaptureOutput,
                       didOutput sampleBuffer: CMSampleBuffer,
                       from connection: AVCaptureConnection) {
        guard isRecording,
              let writer = assetWriter else { return }
        
        let writerInput = (output is AVCaptureVideoDataOutput) ? videoInput : audioInput
        let isVideo = output is AVCaptureVideoDataOutput
        
        switch writer.status {
        case .unknown:
            let timestamp = CMSampleBufferGetPresentationTimeStamp(sampleBuffer)
            
            // Only start session with video buffer to ensure proper synchronization
            if isVideo {
                print("🎥 Starting asset writer session with video buffer")
                writer.startWriting()
                writer.startSession(atSourceTime: timestamp)
                print("📝 Started writing at timestamp: \(timestamp.seconds)")
                
                // Append the first buffer immediately to avoid empty frames
                if let input = writerInput,
                   input.isReadyForMoreMediaData {
                    let success = input.append(sampleBuffer)
                    if !success {
                        print("⚠️ Failed to append first video buffer")
                    }
                }
            }
            
        case .writing:
            if let input = writerInput,
               input.isReadyForMoreMediaData {
                let success = input.append(sampleBuffer)
                if !success {
                    print("⚠️ Failed to append \(isVideo ? "video" : "audio") buffer")
                }
            }
            
        case .failed:
            print("❌ Asset writer failed: \(writer.error?.localizedDescription ?? "unknown error")")
            DispatchQueue.main.async {
                self.error = .recordingFailed
                self.isRecording = false
                self.isProcessingRecording = false
            }
            
        case .completed:
            print("✅ Asset writer completed")
            
        default:
            print("️ Asset writer status: \(writer.status.rawValue)")
        }
    }
    
    func captureOutput(_ output: AVCaptureOutput,
                       didDrop sampleBuffer: CMSampleBuffer,
                       from connection: AVCaptureConnection) {
        let isVideo = output is AVCaptureVideoDataOutput
        print("Dropped \(isVideo ? "video" : "audio") buffer")
    }
}

================
File: camera/Features/Settings/SettingsModel.swift
================
import Foundation
import AVFoundation
import CoreMedia

class SettingsModel: ObservableObject {
    @Published var isAppleLogEnabled: Bool {
        didSet {
            UserDefaults.standard.set(isAppleLogEnabled, forKey: "isAppleLogEnabled")
            NotificationCenter.default.post(name: .appleLogSettingChanged, object: nil)
        }
    }
    
    var isAppleLogSupported: Bool {
        guard let device = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
            return false
        }
        
        // Check if any format supports Apple Log
        return device.formats.contains { format in
            let colorSpaces = format.supportedColorSpaces.map { $0.rawValue }
            return colorSpaces.contains(AVCaptureColorSpace.appleLog.rawValue)
        }
    }
    
    init() {
        self.isAppleLogEnabled = UserDefaults.standard.bool(forKey: "isAppleLogEnabled")
    }
}

extension Notification.Name {
    static let appleLogSettingChanged = Notification.Name("appleLogSettingChanged")
}

================
File: camera/Features/Settings/SettingsView.swift
================
import SwiftUI

struct SettingsView: View {
    @Environment(\.dismiss) private var dismiss
    
    var body: some View {
        NavigationView {
            Form {
                Section(header: Text("Camera Settings")) {
                    // Other settings can go here
                }
            }
            .navigationTitle("Settings")
            .navigationBarItems(trailing: Button("Done") {
                dismiss()
            })
        }
    }
}

#Preview {
    SettingsView()
}

================
File: camera/Preview Content/Preview Assets.xcassets/Contents.json
================
{
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: camera/cameraApp.swift
================
//
//  cameraApp.swift
//  camera
//
//  Created by spencer on 2024-12-22.
//

import SwiftUI

@main
struct cameraApp: App {
    let persistenceController = PersistenceController.shared

    var body: some Scene {
        WindowGroup {
            ContentView()
                .environment(\.managedObjectContext, persistenceController.container.viewContext)
        }
    }
}

================
File: camera/ContentView.swift
================
//
//  ContentView.swift
//  camera
//
//  Created by spencer on 2024-12-22.
//

import SwiftUI
import CoreData
import CoreMedia

struct ContentView: View {
    @StateObject private var viewModel = CameraViewModel()
    @State private var orientation = UIDevice.current.orientation
    
    var body: some View {
        GeometryReader { geometry in
            ZStack {
                if viewModel.isSessionRunning {
                    CameraPreviewView(session: viewModel.session)
                        .ignoresSafeArea()
                        .frame(maxWidth: .infinity, maxHeight: .infinity)
                    
                    VStack {
                        Spacer()
                        
                        // Camera controls
                        Group {
                            if orientation.isPortrait {
                                VStack {
                                    Spacer()
                                    controlsView
                                        .frame(maxWidth: geometry.size.width)
                                }
                            } else {
                                HStack {
                                    Spacer()
                                    controlsView
                                        .frame(maxWidth: geometry.size.width * 0.4)
                                }
                            }
                        }
                    }
                } else {
                    ProgressView("Initializing Camera...")
                }
            }
            .edgesIgnoringSafeArea(.all)
        }
        .alert(item: $viewModel.error) { error in
            Alert(title: Text("Error"),
                  message: Text(error.description),
                  dismissButton: .default(Text("OK")))
        }
        .onRotate { newOrientation in
            orientation = newOrientation
        }
    }
    
    // Extract controls into separate view
    private var controlsView: some View {
        VStack(spacing: 20) {
            HStack {
                Text("WB: \(Int(viewModel.whiteBalance))K")
                Slider(value: $viewModel.whiteBalance,
                       in: 2000...8000,
                       step: 100) { _ in
                    viewModel.updateWhiteBalance(viewModel.whiteBalance)
                }
            }
            
            HStack {
                Text("ISO: \(Int(viewModel.iso))")
                Slider(value: $viewModel.iso,
                       in: viewModel.minISO...viewModel.maxISO,
                       step: 1) { _ in
                    viewModel.updateISO(viewModel.iso)
                }
            }
            
            HStack {
                Text("Shutter: 1/\(Int(viewModel.shutterSpeed.timescale)/Int(viewModel.shutterSpeed.value))")
                Slider(value: .init(get: {
                    Float(viewModel.shutterSpeed.timescale)/Float(viewModel.shutterSpeed.value)
                }, set: { newValue in
                    viewModel.updateShutterSpeed(CMTimeMake(value: 1, timescale: Int32(newValue)))
                }), in: 15...8000, step: 1)
            }
            
            // Add Apple Log toggle if supported
            if viewModel.isAppleLogSupported {
                Toggle(isOn: $viewModel.isAppleLogEnabled) {
                    HStack {
                        Text("Apple Log")
                        if viewModel.isAppleLogEnabled {
                            Image(systemName: "checkmark.circle.fill")
                                .foregroundColor(.green)
                        }
                    }
                }
                .tint(.green)
            }
            
            Button(action: {
                if viewModel.isRecording {
                    viewModel.stopRecording()
                } else {
                    viewModel.startRecording()
                }
            }) {
                Image(systemName: viewModel.isRecording ? "stop.circle" : "record.circle")
                    .font(.system(size: 60))
                    .foregroundColor(viewModel.isRecording ? .white : .red)
                    .opacity(viewModel.isProcessingRecording ? 0.5 : 1.0)
            }
            .disabled(viewModel.isProcessingRecording)
        }
        .padding()
        .background(.ultraThinMaterial)
        .cornerRadius(15)
        .padding()
    }
}

// Add rotation view modifier
struct DeviceRotationViewModifier: ViewModifier {
    let action: (UIDeviceOrientation) -> Void
    
    func body(content: Content) -> some View {
        content.onAppear()
            .onReceive(NotificationCenter.default.publisher(for: UIDevice.orientationDidChangeNotification)) { _ in
                action(UIDevice.current.orientation)
            }
    }
}

extension View {
    func onRotate(perform action: @escaping (UIDeviceOrientation) -> Void) -> some View {
        self.modifier(DeviceRotationViewModifier(action: action))
    }
}

#Preview {
    ContentView().environment(\.managedObjectContext, PersistenceController.preview.container.viewContext)
}

================
File: camera/Info.plist
================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>UIApplicationSceneManifest</key>
	<dict>
		<key>UIApplicationSupportsMultipleScenes</key>
		<false/>
	</dict>
</dict>
</plist>

================
File: camera/Persistence.swift
================
//
//  Persistence.swift
//  camera
//
//  Created by spencer on 2024-12-22.
//

import CoreData

struct PersistenceController {
    static let shared = PersistenceController()

    @MainActor
    static let preview: PersistenceController = {
        let result = PersistenceController(inMemory: true)
        let viewContext = result.container.viewContext
        for _ in 0..<10 {
            let newItem = Item(context: viewContext)
            newItem.timestamp = Date()
        }
        do {
            try viewContext.save()
        } catch {
            // Replace this implementation with code to handle the error appropriately.
            // fatalError() causes the application to generate a crash log and terminate. You should not use this function in a shipping application, although it may be useful during development.
            let nsError = error as NSError
            fatalError("Unresolved error \(nsError), \(nsError.userInfo)")
        }
        return result
    }()

    let container: NSPersistentContainer

    init(inMemory: Bool = false) {
        container = NSPersistentContainer(name: "camera")
        if inMemory {
            container.persistentStoreDescriptions.first!.url = URL(fileURLWithPath: "/dev/null")
        }
        container.loadPersistentStores(completionHandler: { (storeDescription, error) in
            if let error = error as NSError? {
                // Replace this implementation with code to handle the error appropriately.
                // fatalError() causes the application to generate a crash log and terminate. You should not use this function in a shipping application, although it may be useful during development.

                /*
                 Typical reasons for an error here include:
                 * The parent directory does not exist, cannot be created, or disallows writing.
                 * The persistent store is not accessible, due to permissions or data protection when the device is locked.
                 * The device is out of space.
                 * The store could not be migrated to the current model version.
                 Check the error message to determine what the actual problem was.
                 */
                fatalError("Unresolved error \(error), \(error.userInfo)")
            }
        })
        container.viewContext.automaticallyMergesChangesFromParent = true
    }
}

================
File: camera.xcodeproj/project.xcworkspace/contents.xcworkspacedata
================
<?xml version="1.0" encoding="UTF-8"?>
<Workspace
   version = "1.0">
   <FileRef
      location = "self:">
   </FileRef>
</Workspace>

================
File: camera.xcodeproj/xcuserdata/spencer.xcuserdatad/xcschemes/xcschememanagement.plist
================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>SchemeUserState</key>
	<dict>
		<key>camera.xcscheme_^#shared#^_</key>
		<dict>
			<key>orderHint</key>
			<integer>0</integer>
		</dict>
	</dict>
</dict>
</plist>

================
File: camera.xcodeproj/project.pbxproj
================
// !$*UTF8*$!
{
	archiveVersion = 1;
	classes = {
	};
	objectVersion = 77;
	objects = {

/* Begin PBXFileReference section */
		09562D7C2D18A1EC009A9B07 /* camera.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = camera.app; sourceTree = BUILT_PRODUCTS_DIR; };
/* End PBXFileReference section */

/* Begin PBXFileSystemSynchronizedBuildFileExceptionSet section */
		09562DB12D18A28C009A9B07 /* Exceptions for "camera" folder in "camera" target */ = {
			isa = PBXFileSystemSynchronizedBuildFileExceptionSet;
			membershipExceptions = (
				Info.plist,
			);
			target = 09562D7B2D18A1EC009A9B07 /* camera */;
		};
/* End PBXFileSystemSynchronizedBuildFileExceptionSet section */

/* Begin PBXFileSystemSynchronizedRootGroup section */
		09562D7E2D18A1EC009A9B07 /* camera */ = {
			isa = PBXFileSystemSynchronizedRootGroup;
			exceptions = (
				09562DB12D18A28C009A9B07 /* Exceptions for "camera" folder in "camera" target */,
			);
			path = camera;
			sourceTree = "<group>";
		};
/* End PBXFileSystemSynchronizedRootGroup section */

/* Begin PBXFrameworksBuildPhase section */
		09562D792D18A1EC009A9B07 /* Frameworks */ = {
			isa = PBXFrameworksBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXFrameworksBuildPhase section */

/* Begin PBXGroup section */
		09562D732D18A1EC009A9B07 = {
			isa = PBXGroup;
			children = (
				09562D7E2D18A1EC009A9B07 /* camera */,
				09562D7D2D18A1EC009A9B07 /* Products */,
			);
			sourceTree = "<group>";
		};
		09562D7D2D18A1EC009A9B07 /* Products */ = {
			isa = PBXGroup;
			children = (
				09562D7C2D18A1EC009A9B07 /* camera.app */,
			);
			name = Products;
			sourceTree = "<group>";
		};
/* End PBXGroup section */

/* Begin PBXNativeTarget section */
		09562D7B2D18A1EC009A9B07 /* camera */ = {
			isa = PBXNativeTarget;
			buildConfigurationList = 09562D8F2D18A1EE009A9B07 /* Build configuration list for PBXNativeTarget "camera" */;
			buildPhases = (
				09562D782D18A1EC009A9B07 /* Sources */,
				09562D792D18A1EC009A9B07 /* Frameworks */,
				09562D7A2D18A1EC009A9B07 /* Resources */,
			);
			buildRules = (
			);
			dependencies = (
			);
			fileSystemSynchronizedGroups = (
				09562D7E2D18A1EC009A9B07 /* camera */,
			);
			name = camera;
			packageProductDependencies = (
			);
			productName = camera;
			productReference = 09562D7C2D18A1EC009A9B07 /* camera.app */;
			productType = "com.apple.product-type.application";
		};
/* End PBXNativeTarget section */

/* Begin PBXProject section */
		09562D742D18A1EC009A9B07 /* Project object */ = {
			isa = PBXProject;
			attributes = {
				BuildIndependentTargetsInParallel = 1;
				LastSwiftUpdateCheck = 1620;
				LastUpgradeCheck = 1620;
				TargetAttributes = {
					09562D7B2D18A1EC009A9B07 = {
						CreatedOnToolsVersion = 16.2;
					};
				};
			};
			buildConfigurationList = 09562D772D18A1EC009A9B07 /* Build configuration list for PBXProject "camera" */;
			developmentRegion = en;
			hasScannedForEncodings = 0;
			knownRegions = (
				en,
				Base,
			);
			mainGroup = 09562D732D18A1EC009A9B07;
			minimizedProjectReferenceProxies = 1;
			preferredProjectObjectVersion = 77;
			productRefGroup = 09562D7D2D18A1EC009A9B07 /* Products */;
			projectDirPath = "";
			projectRoot = "";
			targets = (
				09562D7B2D18A1EC009A9B07 /* camera */,
			);
		};
/* End PBXProject section */

/* Begin PBXResourcesBuildPhase section */
		09562D7A2D18A1EC009A9B07 /* Resources */ = {
			isa = PBXResourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXResourcesBuildPhase section */

/* Begin PBXSourcesBuildPhase section */
		09562D782D18A1EC009A9B07 /* Sources */ = {
			isa = PBXSourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXSourcesBuildPhase section */

/* Begin XCBuildConfiguration section */
		09562D8D2D18A1EE009A9B07 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				ASSETCATALOG_COMPILER_GENERATE_SWIFT_ASSET_SYMBOL_EXTENSIONS = YES;
				CLANG_ANALYZER_NONNULL = YES;
				CLANG_ANALYZER_NUMBER_OBJECT_CONVERSION = YES_AGGRESSIVE;
				CLANG_CXX_LANGUAGE_STANDARD = "gnu++20";
				CLANG_ENABLE_MODULES = YES;
				CLANG_ENABLE_OBJC_ARC = YES;
				CLANG_ENABLE_OBJC_WEAK = YES;
				CLANG_WARN_BLOCK_CAPTURE_AUTORELEASING = YES;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_COMMA = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_DEPRECATED_OBJC_IMPLEMENTATIONS = YES;
				CLANG_WARN_DIRECT_OBJC_ISA_USAGE = YES_ERROR;
				CLANG_WARN_DOCUMENTATION_COMMENTS = YES;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INFINITE_RECURSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN_NON_LITERAL_NULL_CONVERSION = YES;
				CLANG_WARN_OBJC_IMPLICIT_RETAIN_SELF = YES;
				CLANG_WARN_OBJC_LITERAL_CONVERSION = YES;
				CLANG_WARN_OBJC_ROOT_CLASS = YES_ERROR;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = YES;
				CLANG_WARN_RANGE_LOOP_ANALYSIS = YES;
				CLANG_WARN_STRICT_PROTOTYPES = YES;
				CLANG_WARN_SUSPICIOUS_MOVE = YES;
				CLANG_WARN_UNGUARDED_AVAILABILITY = YES_AGGRESSIVE;
				CLANG_WARN_UNREACHABLE_CODE = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				COPY_PHASE_STRIP = NO;
				DEBUG_INFORMATION_FORMAT = dwarf;
				ENABLE_STRICT_OBJC_MSGSEND = YES;
				ENABLE_TESTABILITY = YES;
				ENABLE_USER_SCRIPT_SANDBOXING = YES;
				GCC_C_LANGUAGE_STANDARD = gnu17;
				GCC_DYNAMIC_NO_PIC = NO;
				GCC_NO_COMMON_BLOCKS = YES;
				GCC_OPTIMIZATION_LEVEL = 0;
				GCC_PREPROCESSOR_DEFINITIONS = (
					"DEBUG=1",
					"$(inherited)",
				);
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES_ERROR;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				IPHONEOS_DEPLOYMENT_TARGET = 18.2;
				LOCALIZATION_PREFERS_STRING_CATALOGS = YES;
				MTL_ENABLE_DEBUG_INFO = INCLUDE_SOURCE;
				MTL_FAST_MATH = YES;
				ONLY_ACTIVE_ARCH = YES;
				SDKROOT = iphoneos;
				SWIFT_ACTIVE_COMPILATION_CONDITIONS = "DEBUG $(inherited)";
				SWIFT_OPTIMIZATION_LEVEL = "-Onone";
			};
			name = Debug;
		};
		09562D8E2D18A1EE009A9B07 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				ASSETCATALOG_COMPILER_GENERATE_SWIFT_ASSET_SYMBOL_EXTENSIONS = YES;
				CLANG_ANALYZER_NONNULL = YES;
				CLANG_ANALYZER_NUMBER_OBJECT_CONVERSION = YES_AGGRESSIVE;
				CLANG_CXX_LANGUAGE_STANDARD = "gnu++20";
				CLANG_ENABLE_MODULES = YES;
				CLANG_ENABLE_OBJC_ARC = YES;
				CLANG_ENABLE_OBJC_WEAK = YES;
				CLANG_WARN_BLOCK_CAPTURE_AUTORELEASING = YES;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_COMMA = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_DEPRECATED_OBJC_IMPLEMENTATIONS = YES;
				CLANG_WARN_DIRECT_OBJC_ISA_USAGE = YES_ERROR;
				CLANG_WARN_DOCUMENTATION_COMMENTS = YES;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INFINITE_RECURSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN_NON_LITERAL_NULL_CONVERSION = YES;
				CLANG_WARN_OBJC_IMPLICIT_RETAIN_SELF = YES;
				CLANG_WARN_OBJC_LITERAL_CONVERSION = YES;
				CLANG_WARN_OBJC_ROOT_CLASS = YES_ERROR;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = YES;
				CLANG_WARN_RANGE_LOOP_ANALYSIS = YES;
				CLANG_WARN_STRICT_PROTOTYPES = YES;
				CLANG_WARN_SUSPICIOUS_MOVE = YES;
				CLANG_WARN_UNGUARDED_AVAILABILITY = YES_AGGRESSIVE;
				CLANG_WARN_UNREACHABLE_CODE = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				COPY_PHASE_STRIP = NO;
				DEBUG_INFORMATION_FORMAT = "dwarf-with-dsym";
				ENABLE_NS_ASSERTIONS = NO;
				ENABLE_STRICT_OBJC_MSGSEND = YES;
				ENABLE_USER_SCRIPT_SANDBOXING = YES;
				GCC_C_LANGUAGE_STANDARD = gnu17;
				GCC_NO_COMMON_BLOCKS = YES;
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES_ERROR;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				IPHONEOS_DEPLOYMENT_TARGET = 18.2;
				LOCALIZATION_PREFERS_STRING_CATALOGS = YES;
				MTL_ENABLE_DEBUG_INFO = NO;
				MTL_FAST_MATH = YES;
				SDKROOT = iphoneos;
				SWIFT_COMPILATION_MODE = wholemodule;
				VALIDATE_PRODUCT = YES;
			};
			name = Release;
		};
		09562D902D18A1EE009A9B07 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;
				ASSETCATALOG_COMPILER_GLOBAL_ACCENT_COLOR_NAME = AccentColor;
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 1;
				DEVELOPMENT_ASSET_PATHS = "\"camera/Preview Content\"";
				DEVELOPMENT_TEAM = 3B883XKLK8;
				ENABLE_PREVIEWS = YES;
				GENERATE_INFOPLIST_FILE = YES;
				INFOPLIST_FILE = camera/Info.plist;
				INFOPLIST_KEY_NSCameraUsageDescription = "This app needs camera access to record video";
				INFOPLIST_KEY_NSMicrophoneUsageDescription = "This app needs microphone access to record audio";
				INFOPLIST_KEY_NSPhotoLibraryAddUsageDescription = "This app needs access to save recorded videos";
				INFOPLIST_KEY_NSPhotoLibraryUsageDescription = "This app needs access to save recorded videos";
				INFOPLIST_KEY_UIApplicationSupportsIndirectInputEvents = YES;
				INFOPLIST_KEY_UILaunchScreen_Generation = YES;
				INFOPLIST_KEY_UISupportedInterfaceOrientations = "UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight UIInterfaceOrientationPortrait";
				INFOPLIST_KEY_UISupportedInterfaceOrientations_iPad = "UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight UIInterfaceOrientationPortrait UIInterfaceOrientationPortraitUpsideDown";
				LD_RUNPATH_SEARCH_PATHS = (
					"$(inherited)",
					"@executable_path/Frameworks",
				);
				MARKETING_VERSION = 1.0;
				PRODUCT_BUNDLE_IDENTIFIER = com.spencershwetz.camera;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SWIFT_EMIT_LOC_STRINGS = YES;
				SWIFT_VERSION = 5.0;
				TARGETED_DEVICE_FAMILY = "1,2";
			};
			name = Debug;
		};
		09562D912D18A1EE009A9B07 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;
				ASSETCATALOG_COMPILER_GLOBAL_ACCENT_COLOR_NAME = AccentColor;
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 1;
				DEVELOPMENT_ASSET_PATHS = "\"camera/Preview Content\"";
				DEVELOPMENT_TEAM = 3B883XKLK8;
				ENABLE_PREVIEWS = YES;
				GENERATE_INFOPLIST_FILE = YES;
				INFOPLIST_FILE = camera/Info.plist;
				INFOPLIST_KEY_NSCameraUsageDescription = "This app needs camera access to record video";
				INFOPLIST_KEY_NSMicrophoneUsageDescription = "This app needs microphone access to record audio";
				INFOPLIST_KEY_NSPhotoLibraryAddUsageDescription = "This app needs access to save recorded videos";
				INFOPLIST_KEY_NSPhotoLibraryUsageDescription = "This app needs access to save recorded videos";
				INFOPLIST_KEY_UIApplicationSupportsIndirectInputEvents = YES;
				INFOPLIST_KEY_UILaunchScreen_Generation = YES;
				INFOPLIST_KEY_UISupportedInterfaceOrientations = "UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight UIInterfaceOrientationPortrait";
				INFOPLIST_KEY_UISupportedInterfaceOrientations_iPad = "UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight UIInterfaceOrientationPortrait UIInterfaceOrientationPortraitUpsideDown";
				LD_RUNPATH_SEARCH_PATHS = (
					"$(inherited)",
					"@executable_path/Frameworks",
				);
				MARKETING_VERSION = 1.0;
				PRODUCT_BUNDLE_IDENTIFIER = com.spencershwetz.camera;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SWIFT_EMIT_LOC_STRINGS = YES;
				SWIFT_VERSION = 5.0;
				TARGETED_DEVICE_FAMILY = "1,2";
			};
			name = Release;
		};
/* End XCBuildConfiguration section */

/* Begin XCConfigurationList section */
		09562D772D18A1EC009A9B07 /* Build configuration list for PBXProject "camera" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				09562D8D2D18A1EE009A9B07 /* Debug */,
				09562D8E2D18A1EE009A9B07 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		09562D8F2D18A1EE009A9B07 /* Build configuration list for PBXNativeTarget "camera" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				09562D902D18A1EE009A9B07 /* Debug */,
				09562D912D18A1EE009A9B07 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
/* End XCConfigurationList section */
	};
	rootObject = 09562D742D18A1EC009A9B07 /* Project object */;
}
