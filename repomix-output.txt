This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-03-04T23:14:34.563Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
camera/
  Assets.xcassets/
    AccentColor.colorset/
      Contents.json
    AppIcon.appiconset/
      Contents.json
    Contents.json
  camera.xcdatamodeld/
    camera.xcdatamodel/
      contents
    .xccurrentversion
  Core/
    Extensions/
      CIContext+Shared.swift
  Features/
    Camera/
      CameraError.swift
      CameraPreviewView.swift
      CameraViewModel.swift
      DocumentPicker.swift
      ShutterAngle.swift
      VideoOutputDelegate.swift
    LUT/
      CubeLUTLoader.swift
      LUTManager.swift
    Settings/
      SettingsModel.swift
      SettingsView.swift
  Preview Content/
    Preview Assets.xcassets/
      Contents.json
  Resources/
    TestLUT.cube
  cameraApp.swift
  ContentView.swift
  Info.plist
  Persistence.swift
camera.xcodeproj/
  project.xcworkspace/
    contents.xcworkspacedata
  xcuserdata/
    spencer.xcuserdatad/
      xcdebugger/
        Breakpoints_v2.xcbkptlist
      xcschemes/
        xcschememanagement.plist
  project.pbxproj

================================================================
Repository Files
================================================================

================
File: camera/Assets.xcassets/AccentColor.colorset/Contents.json
================
{
  "colors" : [
    {
      "idiom" : "universal"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: camera/Assets.xcassets/AppIcon.appiconset/Contents.json
================
{
  "images" : [
    {
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    },
    {
      "appearances" : [
        {
          "appearance" : "luminosity",
          "value" : "dark"
        }
      ],
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    },
    {
      "appearances" : [
        {
          "appearance" : "luminosity",
          "value" : "tinted"
        }
      ],
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: camera/Assets.xcassets/Contents.json
================
{
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: camera/camera.xcdatamodeld/camera.xcdatamodel/contents
================
<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<model type="com.apple.IDECoreDataModeler.DataModel" documentVersion="1.0" lastSavedToolsVersion="1" systemVersion="11A491" minimumToolsVersion="Automatic" sourceLanguage="Swift" usedWithCloudKit="false" userDefinedModelVersionIdentifier="">
    <entity name="Item" representedClassName="Item" syncable="YES" codeGenerationType="class">
        <attribute name="timestamp" optional="YES" attributeType="Date" usesScalarValueType="NO"/>
    </entity>
    <elements>
        <element name="Item" positionX="-63" positionY="-18" width="128" height="44"/>
    </elements>
</model>

================
File: camera/camera.xcdatamodeld/.xccurrentversion
================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>_XCCurrentVersionName</key>
	<string>camera.xcdatamodel</string>
</dict>
</plist>

================
File: camera/Core/Extensions/CIContext+Shared.swift
================
import CoreImage

extension CIContext {
    static let shared: CIContext = {
        let options = [
            CIContextOption.workingColorSpace: CGColorSpace(name: CGColorSpace.displayP3)!,
            CIContextOption.useSoftwareRenderer: false
        ]
        return CIContext(options: options)
    }()
}

================
File: camera/Features/Camera/CameraError.swift
================
import Foundation

enum CameraError: Error, Identifiable {
    case cameraUnavailable
    case setupFailed
    case configurationFailed
    case recordingFailed
    case savingFailed
    case whiteBalanceError
    case custom(message: String)
    
    var id: String { description }
    
    var description: String {
        switch self {
        case .cameraUnavailable:
            return "Camera device not available"
        case .setupFailed:
            return "Failed to setup camera"
        case .configurationFailed:
            return "Failed to configure camera settings"
        case .recordingFailed:
            return "Failed to record video"
        case .savingFailed:
            return "Failed to save video to photo library"
        case .whiteBalanceError:
            return "Failed to adjust white balance settings"
        case .custom(let message):
            return message
        }
    }
}

================
File: camera/Features/Camera/CameraPreviewView.swift
================
import SwiftUI
import AVFoundation
import MetalKit
import CoreImage

struct CameraPreviewView: UIViewRepresentable {
    let session: AVCaptureSession
    @ObservedObject var lutManager: LUTManager
    let viewModel: CameraViewModel
    
    func makeUIView(context: Context) -> PreviewView {
        let view = PreviewView()
        view.backgroundColor = .black
        view.autoresizingMask = [.flexibleWidth, .flexibleHeight]
        
        // Connect the session to the coordinator
        context.coordinator.session = session
        context.coordinator.previewView = view
        
        // Configure video output
        let videoOutput = AVCaptureVideoDataOutput()
        videoOutput.videoSettings = [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
        ]
        videoOutput.setSampleBufferDelegate(context.coordinator, queue: DispatchQueue(label: "videoQueue"))
        
        if session.canAddOutput(videoOutput) {
            session.addOutput(videoOutput)
        }
        
        return view
    }
    
    func updateUIView(_ uiView: PreviewView, context: Context) {
        // Update orientation if needed
        updatePreviewOrientation(uiView)
    }
    
    func makeCoordinator() -> Coordinator {
        Coordinator(parent: self)
    }
    
    /// Compute the rotation angle based on the window scene orientation
    private func updatePreviewOrientation(_ previewView: PreviewView) {
        var angle: CGFloat = 90 // default portrait rotation
        if let scene = UIApplication.shared.connectedScenes.first as? UIWindowScene {
            switch scene.interfaceOrientation {
            case .portrait:
                angle = 90
            case .landscapeRight:
                angle = 0
            case .landscapeLeft:
                angle = 180
            case .portraitUpsideDown:
                angle = 270
            default:
                angle = 90
            }
        }
        previewView.videoRotationAngle = angle
    }
    
    class Coordinator: NSObject, AVCaptureVideoDataOutputSampleBufferDelegate {
        let parent: CameraPreviewView
        let context = CIContext.shared
        var session: AVCaptureSession?
        weak var previewView: PreviewView?
        // Remove rotation transform here so that we pass the raw CIImage to the view
        
        init(parent: CameraPreviewView) {
            self.parent = parent
            super.init()
        }
        
        func captureOutput(_ output: AVCaptureOutput,
                           didOutput sampleBuffer: CMSampleBuffer,
                           from connection: AVCaptureConnection) {
            guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
                print("‚ùå Failed to get pixel buffer from sample buffer")
                return
            }
            
            let width = CVPixelBufferGetWidth(pixelBuffer)
            let height = CVPixelBufferGetHeight(pixelBuffer)
            print("üìê Buffer dimensions: \(width)x\(height)")
            print("üé® Pixel format: \(CVPixelBufferGetPixelFormatType(pixelBuffer))")
            
            // Create CIImage without any rotation transform
            let ciImage = CIImage(cvPixelBuffer: pixelBuffer)
            print("üåÑ CIImage created - extent: \(ciImage.extent)")
            
            // Apply LUT if available
            var finalImage = ciImage
            if let lutFilter = parent.lutManager.currentLUTFilter {
                lutFilter.setValue(finalImage, forKey: kCIInputImageKey)
                if let outputImage = lutFilter.outputImage {
                    finalImage = outputImage
                    print("‚úÖ LUT applied successfully")
                } else {
                    print("‚ùå LUT application failed - nil output")
                }
            }
            
            // Store the unrotated image; rotation/scaling will be applied in the Metal renderer.
            DispatchQueue.main.async { [weak self] in
                guard let self = self, let previewView = self.previewView else { return }
                previewView.currentCIImage = finalImage
                previewView.setNeedsDisplay()
            }
        }
    }
    
    class PreviewView: UIView {
        // MetalKit view for rendering
        private var metalView: MTKView?
        var renderer: MetalRenderer?
        
        // New property to control rotation (in degrees)
        var videoRotationAngle: CGFloat = 90 {
            didSet {
                renderer?.videoRotationAngle = videoRotationAngle
            }
        }
        
        var currentCIImage: CIImage?
        
        override init(frame: CGRect) {
            super.init(frame: frame)
            setupMetalView()
        }
        
        required init?(coder: NSCoder) {
            super.init(coder: coder)
            setupMetalView()
        }
        
        private func setupMetalView() {
            guard let device = MTLCreateSystemDefaultDevice() else {
                print("‚ùå Metal is not supported on this device")
                return
            }
            
            let mtkView = MTKView(frame: bounds, device: device)
            mtkView.framebufferOnly = false
            mtkView.colorPixelFormat = .bgra8Unorm
            mtkView.autoresizingMask = [.flexibleWidth, .flexibleHeight]
            
            renderer = MetalRenderer(metalDevice: device, pixelFormat: mtkView.colorPixelFormat)
            // Initialize with the default rotation
            renderer?.videoRotationAngle = videoRotationAngle
            mtkView.delegate = renderer
            
            addSubview(mtkView)
            self.metalView = mtkView
        }
        
        override func layoutSubviews() {
            super.layoutSubviews()
            metalView?.frame = bounds
        }
        
        override func setNeedsDisplay() {
            if let _ = currentCIImage {
                renderer?.currentCIImage = currentCIImage
                metalView?.draw()
            }
        }
    }
    
    class MetalRenderer: NSObject, MTKViewDelegate {
        private let commandQueue: MTLCommandQueue
        private let ciContext: CIContext
        var currentCIImage: CIImage?
        // New property to store the rotation angle (in degrees)
        var videoRotationAngle: CGFloat = 90
        
        init?(metalDevice: MTLDevice, pixelFormat: MTLPixelFormat) {
            guard let queue = metalDevice.makeCommandQueue() else {
                return nil
            }
            self.commandQueue = queue
            self.ciContext = CIContext(mtlDevice: metalDevice, options: [.cacheIntermediates: false])
            super.init()
        }
        
        func mtkView(_ view: MTKView, drawableSizeWillChange size: CGSize) {
            // Handle view size changes if needed
        }
        
        func draw(in view: MTKView) {
            guard let drawable = view.currentDrawable,
                  let image = currentCIImage,
                  let commandBuffer = commandQueue.makeCommandBuffer() else {
                return
            }
            
            // 1. Apply rotation using the videoRotationAngle property.
            let radians = videoRotationAngle * CGFloat.pi / 180
            let rotatedImage = image.transformed(by: CGAffineTransform(rotationAngle: radians))
            
            // 2. Scale the rotated image to fill the drawable.
            let imageExtent = rotatedImage.extent
            let drawableSize = view.drawableSize
            let scaleX = drawableSize.width / imageExtent.width
            let scaleY = drawableSize.height / imageExtent.height
            let scale = max(scaleX, scaleY)
            let scaledImage = rotatedImage.transformed(by: CGAffineTransform(scaleX: scale, y: scale))
            
            // 3. Center the image.
            let centeredX = (drawableSize.width - scaledImage.extent.width) / 2.0
            let centeredY = (drawableSize.height - scaledImage.extent.height) / 2.0
            let centeredImage = scaledImage.transformed(by: CGAffineTransform(translationX: centeredX, y: centeredY))
            
            // Render the final image.
            ciContext.render(centeredImage,
                             to: drawable.texture,
                             commandBuffer: commandBuffer,
                             bounds: CGRect(origin: .zero, size: drawableSize),
                             colorSpace: CGColorSpaceCreateDeviceRGB())
            
            commandBuffer.present(drawable)
            commandBuffer.commit()
        }
    }
}

================
File: camera/Features/Camera/CameraViewModel.swift
================
import AVFoundation
import SwiftUI
import Photos
import VideoToolbox
import CoreVideo
import os.log
import CoreImage

class CameraViewModel: NSObject, ObservableObject {
    enum Status {
        case unknown
        case running
        case failed
        case unauthorized
    }
    @Published private(set) var status: Status = .unknown
    
    enum CaptureMode {
        case photo
        case video
    }
    @Published var captureMode: CaptureMode = .video
    
    private let logger = Logger(subsystem: "com.camera", category: "CameraViewModel")
    
    @Published var isSessionRunning = false
    @Published var error: CameraError?
    @Published var whiteBalance: Float = 5000 // Kelvin
    @Published var iso: Float = 100
    @Published var shutterSpeed: CMTime = CMTimeMake(value: 1, timescale: 60) // Initialize for 180¬∞ at 30fps
    @Published var isRecording = false
    @Published var recordingFinished = false
    @Published var isSettingsPresented = false
    @Published var isProcessingRecording = false
    
    // Enable Apple Log (4K ProRes) by default if device supports it
    @Published var isAppleLogEnabled = false {
        didSet {
            print("\n=== Apple Log Toggle ===")
            print("üîÑ Status: \(status)")
            print("üìπ Capture Mode: \(captureMode)")
            print("‚úÖ Attempting to set Apple Log to: \(isAppleLogEnabled)")
            
            guard status == .running, captureMode == .video else {
                print("‚ùå Cannot configure Apple Log - Status or mode incorrect")
                print("Required: status == .running (is: \(status))")
                print("Required: captureMode == .video (is: \(captureMode))")
                return
            }
            
            Task {
                do {
                    if isAppleLogEnabled {
                        print("üé• Configuring Apple Log...")
                        try await configureAppleLog()
                    } else {
                        print("‚Ü©Ô∏è Resetting Apple Log...")
                        try await resetAppleLog()
                    }
                } catch {
                    await MainActor.run {
                        self.error = .configurationFailed
                    }
                    logger.error("Failed to configure Apple Log: \(error.localizedDescription)")
                    print("‚ùå Apple Log configuration failed: \(error)")
                }
            }
            print("=== End Apple Log Toggle ===\n")
        }
    }
    
    @Published private(set) var isAppleLogSupported = false
    
    let session = AVCaptureSession()
    private var device: AVCaptureDevice?
    
    // Add movie file output
    private let movieOutput = AVCaptureMovieFileOutput()
    private var currentRecordingURL: URL?
    
    private var defaultFormat: AVCaptureDevice.Format?
    
    var minISO: Float {
        device?.activeFormat.minISO ?? 50
    }
    var maxISO: Float {
        device?.activeFormat.maxISO ?? 1600
    }
    
    // Add new property for frame rate
    @Published var selectedFrameRate: Double = 30.0
    
    // Add available frame rates
    let availableFrameRates: [Double] = [23.976, 24.0, 25.0, 29.97, 30.0]
    
    private var orientationObserver: NSObjectProtocol?
    
    // Add property to track interface orientation
    @Published private(set) var currentInterfaceOrientation: UIInterfaceOrientation = .portrait
    
    private let processingQueue = DispatchQueue(
        label: "com.camera.processing",
        qos: .userInitiated,
        attributes: [],
        autoreleaseFrequency: .workItem
    )
    
    // Add properties for frame rate monitoring
    private var lastFrameTimestamp: CFAbsoluteTime = 0
    private var lastFrameTime: CMTime?
    private var frameCount: Int = 0
    private var frameRateAccumulator: Double = 0
    private var frameRateUpdateInterval: Int = 30 // Update every 30 frames
    
    // Add property to store supported frame rate range
    private var supportedFrameRateRange: AVFrameRateRange? {
        device?.activeFormat.videoSupportedFrameRateRanges.first
    }
    
    // Add properties for advanced configuration
    private var videoConfiguration: [String: Any] = [
        AVVideoCodecKey: AVVideoCodecType.proRes422,
        AVVideoCompressionPropertiesKey: [
            AVVideoAverageBitRateKey: 50_000_000, // 50 Mbps
            AVVideoMaxKeyFrameIntervalKey: 1, // Every frame is keyframe
            AVVideoAllowFrameReorderingKey: false,
            AVVideoExpectedSourceFrameRateKey: 30
        ]
    ]
    
    // Add these constants
    private struct FrameRates {
        // Non-integer frame rates need precise representation
        // For 23.976 fps, the exact fraction is 24000/1001 ‚âà 23.976
        static let ntsc23_976 = CMTime(value: 1001, timescale: 24000)  // 23.976 fps (24000/1001)
        static let ntsc29_97 = CMTime(value: 1001, timescale: 30000)   // 29.97 fps
        static let film24 = CMTime(value: 1, timescale: 24)            // 24 fps
        static let pal25 = CMTime(value: 1, timescale: 25)             // 25 fps
        static let ntsc30 = CMTime(value: 1, timescale: 30)            // 30 fps
    }
    
    @Published var currentTint: Double = 0.0 // Range: -150 to +150
    private let tintRange = (-150.0...150.0)
    
    private var videoDeviceInput: AVCaptureDeviceInput?
    
    @Published var isAutoExposureEnabled: Bool = true {
        didSet {
            updateExposureMode()
        }
    }
    
    // Add LUT Manager
    @Published var lutManager = LUTManager()
    private var ciContext = CIContext()
    
    override init() {
        super.init()
        print("\n=== Camera Initialization ===")
        
        do {
            try setupSession()
            
            // Print device capabilities
            if let device = device {
                print("üìä Device Capabilities:")
                print("- Name: \(device.localizedName)")
                print("- Model ID: \(device.modelID)")
                
    
                
                isAppleLogSupported = device.formats.contains { format in
                    format.supportedColorSpaces.contains(.appleLog)
                }
                print("\n‚úÖ Apple Log Support: \(isAppleLogSupported)")
            }
            print("=== End Initialization ===\n")
            
            // Store default format
            if let device = device {
                defaultFormat = device.activeFormat
            }
            
            // Check Apple Log support
            isAppleLogSupported = device?.formats.contains { format in
                format.supportedColorSpaces.contains(.appleLog)
            } ?? false
        } catch {
            self.error = .setupFailed
            print("Failed to setup session: \(error)")
        }
        
        // Add orientation observer
        orientationObserver = NotificationCenter.default.addObserver(
            forName: UIDevice.orientationDidChangeNotification,
            object: nil,
            queue: .main) { [weak self] _ in
                guard let self = self,
                      let connection = self.movieOutput.connection(with: .video) else { return }
                self.updateVideoOrientation(connection)
        }
        
        // After other initialization, set initial shutter angle to 180¬∞
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            self.updateShutterAngle(180.0) // Set initial shutter angle to 180¬∞
        }
        
        print("üì± LUT Loading: No default LUTs will be loaded")
        // User must import their own LUTs
        
        // Configure camera session
    }
    
    deinit {
        if let observer = orientationObserver {
            NotificationCenter.default.removeObserver(observer)
        }
    }
    
    /// Returns a 4K (3840x2160) AppleProRes422 format that also supports Apple Log
    private func findBestAppleLogFormat(_ device: AVCaptureDevice) -> AVCaptureDevice.Format? {
        return device.formats.first { format in
            let desc = format.formatDescription
            let dimensions = CMVideoFormatDescriptionGetDimensions(desc)
            let codecType = CMFormatDescriptionGetMediaSubType(desc)
            
            let is4K = (dimensions.width == 3840 && dimensions.height == 2160)
            let isProRes422 = (codecType == kCMVideoCodecType_AppleProRes422) // 'x422'
            let hasAppleLog = format.supportedColorSpaces.contains(.appleLog)
            
            return is4K && isProRes422 && hasAppleLog
        }
    }
    
    private func configureAppleLog() async throws {
        guard let device = device else {
            print("‚ùå No camera device available")
            return
        }
        
        print("\n=== Apple Log Configuration ===")
        print("üé• Current device: \(device.localizedName)")
        print("üìä Current format: \(device.activeFormat.formatDescription)")
        print("üé® Current color space: \(device.activeColorSpace.rawValue)")
        print("üé® Wide color enabled: \(session.automaticallyConfiguresCaptureDeviceForWideColor)")
        
        // Ensure wide color is disabled
        session.automaticallyConfiguresCaptureDeviceForWideColor = false
        
        // Check if format supports Apple Log
        let supportsAppleLog = device.formats.contains { format in
            format.supportedColorSpaces.contains(.appleLog)
        }
        print("‚úì Device supports Apple Log: \(supportsAppleLog)")
        
        do {
            session.stopRunning()
            print("‚è∏Ô∏è Session stopped for reconfiguration")
            
            try await Task.sleep(for: .milliseconds(100))
            session.beginConfiguration()
            
            try device.lockForConfiguration()
            defer {
                device.unlockForConfiguration()
                session.commitConfiguration()
                
                // Fix orientation after configuration
                if let videoConnection = movieOutput.connection(with: .video) {
                    updateVideoOrientation(videoConnection)
                }
                
                session.startRunning()
            }
            
            // Find best Apple Log format
            if let format = device.formats.first(where: {
                let desc = $0.formatDescription
                let dimensions = CMVideoFormatDescriptionGetDimensions(desc)
                let codecType = CMFormatDescriptionGetMediaSubType(desc)
                
                let is4K = (dimensions.width == 3840 && dimensions.height == 2160)
                let isProRes = (codecType == kCMVideoCodecType_AppleProRes422 ||
                              codecType == kCMVideoCodecType_AppleProRes422HQ ||
                              codecType == 2016686642)
                let hasAppleLog = $0.supportedColorSpaces.contains(.appleLog)
                
                return (is4K || dimensions.width >= 1920) && isProRes && hasAppleLog
            }) {
                print("‚úÖ Found suitable Apple Log format")
                
                let duration = CMTimeMake(value: 1000, timescale: Int32(selectedFrameRate * 1000))
                device.activeVideoMinFrameDuration = duration
                device.activeVideoMaxFrameDuration = duration
                
                device.activeFormat = format
                device.activeColorSpace = .appleLog
                print("üé® Set color space to Apple Log")
                
                print("‚úÖ Successfully configured Apple Log format")
            } else {
                print("‚ùå No suitable Apple Log format found")
                throw CameraError.configurationFailed
            }
            
            print("üíæ Configuration committed")
            print("‚ñ∂Ô∏è Session restarted")
            
        } catch {
            print("‚ùå Error configuring Apple Log: \(error.localizedDescription)")
            device.unlockForConfiguration()
            session.commitConfiguration()
            session.startRunning()
            await MainActor.run {
                self.error = .configurationFailed
            }
            print("üîÑ Attempting session recovery")
            throw error
        }
        
        print("=== End Apple Log Configuration ===\n")
    }
    
    private func resetAppleLog() async throws {
        guard let device = device else {
            print("‚ùå No camera device available")
            return
        }
        
        print("\n=== Resetting Apple Log Configuration ===")
        print("üé® Wide color enabled: \(session.automaticallyConfiguresCaptureDeviceForWideColor)")
        
        // Ensure wide color is disabled
        session.automaticallyConfiguresCaptureDeviceForWideColor = false
        
        do {
            session.stopRunning()
            session.beginConfiguration()
            
            try device.lockForConfiguration()
            defer {
                device.unlockForConfiguration()
                session.commitConfiguration()
                
                if let videoConnection = movieOutput.connection(with: .video) {
                    updateVideoOrientation(videoConnection)
                }
                
                session.startRunning()
            }
            
            if let defaultFormat = defaultFormat {
                device.activeFormat = defaultFormat
            }
            device.activeColorSpace = .sRGB
            
            session.commitConfiguration()
            session.startRunning()
            
            print("‚úÖ Successfully reset to sRGB color space")
        } catch {
            print("‚ùå Error resetting Apple Log: \(error.localizedDescription)")
            self.error = .configurationFailed
            session.startRunning()
        }
        
        print("=== End Reset ===\n")
    }
    
    private func setupSession() throws {
        session.automaticallyConfiguresCaptureDeviceForWideColor = false
        session.beginConfiguration()
        
        guard let videoDevice = AVCaptureDevice.default(.builtInWideAngleCamera,
                                                    for: .video,
                                                    position: .back) else {
            error = .cameraUnavailable
            status = .failed
            session.commitConfiguration()
            return
        }
        
        self.device = videoDevice
        
        do {
            let input = try AVCaptureDeviceInput(device: videoDevice)
            self.videoDeviceInput = input
            
            // Configure Apple Log if enabled
            if isAppleLogEnabled, let appleLogFormat = findBestAppleLogFormat(videoDevice) {
                let frameRateRange = appleLogFormat.videoSupportedFrameRateRanges.first!
                try videoDevice.lockForConfiguration()
                videoDevice.activeVideoMinFrameDuration = CMTime(value: 1, timescale: Int32(frameRateRange.maxFrameRate))
                videoDevice.activeVideoMaxFrameDuration = CMTime(value: 1, timescale: Int32(frameRateRange.minFrameRate))
                videoDevice.activeFormat = appleLogFormat
                videoDevice.activeColorSpace = .appleLog
                print("Initial setup: Enabled Apple Log in 4K ProRes format")
            }
            
            if session.canAddInput(input) {
                session.addInput(input)
            }
            
            if let audioDevice = AVCaptureDevice.default(for: .audio),
               let audioInput = try? AVCaptureDeviceInput(device: audioDevice),
               session.canAddInput(audioInput) {
                session.addInput(audioInput)
            }
            
            if session.canAddOutput(movieOutput) {
                session.addOutput(movieOutput)
                
                movieOutput.movieFragmentInterval = .invalid
                
                if let connection = movieOutput.connection(with: .video) {
                    if connection.isVideoStabilizationSupported {
                        connection.preferredVideoStabilizationMode = .auto
                    }
                    updateVideoOrientation(connection)
                }
            }
            
            if let device = device {
                try device.lockForConfiguration()
                let duration = CMTimeMake(value: 1000, timescale: Int32(selectedFrameRate * 1000))
                device.activeVideoMinFrameDuration = duration
                device.activeVideoMaxFrameDuration = duration
                device.unlockForConfiguration()
            }
            
        } catch {
            print("Error setting up camera: \(error)")
            self.error = .setupFailed
            session.commitConfiguration()
            return
        }
        
        session.commitConfiguration()
        
        if session.canSetSessionPreset(.hd4K3840x2160) {
            session.sessionPreset = .hd4K3840x2160
        } else if session.canSetSessionPreset(.hd1920x1080) {
            session.sessionPreset = .hd1920x1080
        }
        
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            self?.session.startRunning()
            DispatchQueue.main.async {
                self?.isSessionRunning = self?.session.isRunning ?? false
                self?.status = .running
            }
        }
        
        isAppleLogSupported = device?.formats.contains { format in
            format.supportedColorSpaces.contains(.appleLog)
        } ?? false
        
        defaultFormat = device?.activeFormat
    }
    
    func updateWhiteBalance(_ temperature: Float) {
        guard let device = device else { return }
        do {
            try device.lockForConfiguration()
            let tnt = AVCaptureDevice.WhiteBalanceTemperatureAndTintValues(temperature: temperature, tint: 0.0)
            var gains = device.deviceWhiteBalanceGains(for: tnt)
            let maxGain = device.maxWhiteBalanceGain
            
            gains.redGain   = min(max(1.0, gains.redGain), maxGain)
            gains.greenGain = min(max(1.0, gains.greenGain), maxGain)
            gains.blueGain  = min(max(1.0, gains.blueGain), maxGain)
            
            device.setWhiteBalanceModeLocked(with: gains) { _ in }
            device.unlockForConfiguration()
            
            whiteBalance = temperature
        } catch {
            print("White balance error: \(error)")
            self.error = .configurationFailed
        }
    }
    
    func updateISO(_ iso: Float) {
        guard let device = device else { return }
        do {
            try device.lockForConfiguration()
            let clamped = min(max(device.activeFormat.minISO, iso), device.activeFormat.maxISO)
            device.setExposureModeCustom(duration: device.exposureDuration, iso: clamped) { _ in }
            device.unlockForConfiguration()
            self.iso = clamped
        } catch {
            print("ISO error: \(error)")
            self.error = .configurationFailed
        }
    }
    
    func updateShutterSpeed(_ speed: CMTime) {
        guard let device = device else { return }
        do {
            try device.lockForConfiguration()
            device.setExposureModeCustom(duration: speed, iso: device.iso) { _ in }
            device.unlockForConfiguration()
            
            DispatchQueue.main.async {
                self.shutterSpeed = speed
            }
        } catch {
            print("‚ùå Shutter speed error: \(error)")
            self.error = .configurationFailed
        }
    }
    
    func startRecording() {
        guard !isRecording && !isProcessingRecording else {
            print("Cannot start recording: Already in progress or processing")
            return
        }
        
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let videoName = "recording-\(Date().timeIntervalSince1970).mov"
        let videoPath = documentsPath.appendingPathComponent(videoName)
        currentRecordingURL = videoPath
        
        movieOutput.startRecording(to: videoPath, recordingDelegate: self)
        isRecording = true
        print("Starting recording to: \(videoPath.path)")
    }
    
    func stopRecording() {
        guard isRecording else {
            print("Cannot stop recording: No ongoing recording")
            return
        }
        
        print("Stopping recording...")
        isProcessingRecording = true
        movieOutput.stopRecording()
    }
    
    private func updateVideoOrientation(_ connection: AVCaptureConnection) {
        let requiredAngles: [CGFloat] = [0, 90, 180, 270]
        let supportsRotation = requiredAngles.allSatisfy { angle in
            connection.isVideoRotationAngleSupported(angle)
        }
        
        guard supportsRotation else { return }
        
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            
            if let windowScene = UIApplication.shared.connectedScenes.first as? UIWindowScene {
                let interfaceOrientation = windowScene.interfaceOrientation
                self.currentInterfaceOrientation = interfaceOrientation
                
                switch interfaceOrientation {
                case .portrait:
                    connection.videoRotationAngle = 90
                case .portraitUpsideDown:
                    connection.videoRotationAngle = 270
                case .landscapeLeft:
                    connection.videoRotationAngle = 180
                case .landscapeRight:
                    connection.videoRotationAngle = 0
                default:
                    connection.videoRotationAngle = 90
                }
            }
            
            if connection.isVideoMirroringSupported {
                connection.isVideoMirrored = false
            }
        }
    }
    
    private func findCompatibleFormat(for fps: Double) -> AVCaptureDevice.Format? {
        guard let device = device else { return nil }
        
        // For 23.976 fps, we need to be more flexible with the range check
        // Some devices might report slightly different values like 23.97 or 23.98
        let targetFps = fps
        let tolerance = 0.01 // Allow for small rounding differences
        
        let formats = device.formats.filter { format in
            let dimensions = CMVideoFormatDescriptionGetDimensions(format.formatDescription)
            let isHighRes = dimensions.width >= 1920
            let supportsFrameRate = format.videoSupportedFrameRateRanges.contains { range in
                // For 23.976 fps specifically, use a slightly more flexible check
                if abs(targetFps - 23.976) < 0.001 {
                    // Check if any range contains ~23.976 fps with tolerance
                    return range.minFrameRate <= (targetFps - tolerance) && 
                           (targetFps + tolerance) <= range.maxFrameRate
                } else {
                    // Standard check for other frame rates
                    return range.minFrameRate <= targetFps && targetFps <= range.maxFrameRate
                }
            }
            
            if isAppleLogEnabled {
                return isHighRes && supportsFrameRate && format.supportedColorSpaces.contains(.appleLog)
            }
            return isHighRes && supportsFrameRate
        }
        
        return formats.first
    }
    
    func updateFrameRate(_ fps: Double) {
        guard let device = device else { return }
        
        do {
            guard let compatibleFormat = findCompatibleFormat(for: fps) else {
                print("‚ùå No compatible format found for \(fps) fps")
                // Set error to allow user feedback
                DispatchQueue.main.async {
                    self.error = .configurationFailed(message: "This device doesn't support \(fps) fps recording")
                }
                return
            }
            
            try device.lockForConfiguration()
            
            if device.activeFormat != compatibleFormat {
                print("Switching to compatible format...")
                device.activeFormat = compatibleFormat
            }
            
            let frameDuration: CMTime
            switch fps {
            case 23.976:
                // For 23.976 fps, use the precise fraction 24000/1001
                frameDuration = FrameRates.ntsc23_976
                print("Setting 23.976 fps with duration \(FrameRates.ntsc23_976.value)/\(FrameRates.ntsc23_976.timescale)")
            case 29.97:
                frameDuration = FrameRates.ntsc29_97
            case 24:
                frameDuration = FrameRates.film24
            case 25:
                frameDuration = FrameRates.pal25
            case 30:
                frameDuration = FrameRates.ntsc30
            default:
                frameDuration = CMTimeMake(value: 1, timescale: Int32(fps))
            }
            
            // Set both min and max durations to lock the frame rate
            device.activeVideoMinFrameDuration = frameDuration
            device.activeVideoMaxFrameDuration = frameDuration
            
            DispatchQueue.main.async { [weak self] in
                guard let self = self else { return }
                self.selectedFrameRate = fps
                self.frameCount = 0
                self.frameRateAccumulator = 0
                self.lastFrameTime = nil
            }
            
            device.unlockForConfiguration()
            
            // Preserve current shutter angle by updating the shutter speed
            let currentAngle = shutterAngle
            updateShutterAngle(currentAngle)
        } catch {
            print("‚ùå Frame rate error: \(error)")
            self.error = .configurationFailed(message: "Failed to set \(fps) fps: \(error.localizedDescription)")
        }
    }
    
    private func adjustFrameRatePrecision(currentFPS: Double) {
        let deviation = abs(currentFPS - selectedFrameRate) / selectedFrameRate
        guard deviation > 0.02 else { return }
        
        let now = Date().timeIntervalSince1970
        guard (now - lastAdjustmentTime) > 1.0 else { return }
        
        lastAdjustmentTime = now
        
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            self.updateFrameRate(self.selectedFrameRate)
        }
    }
    
    private var lastAdjustmentTime: TimeInterval = 0
    
    func updateInterfaceOrientation() {
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            if let windowScene = UIApplication.shared.connectedScenes.first as? UIWindowScene {
                self.currentInterfaceOrientation = windowScene.interfaceOrientation
            }
        }
    }
    
    private func configureHDR() {
        guard let device = device,
              device.activeFormat.isVideoHDRSupported else { return }
        
        do {
            try device.lockForConfiguration()
            device.automaticallyAdjustsVideoHDREnabled = false
            device.isVideoHDREnabled = true
            device.unlockForConfiguration()
        } catch {
            print("Error configuring HDR: \(error)")
        }
    }
    
    private func optimizeVideoCapture() {
        guard let device = device else { return }
        
        do {
            try device.lockForConfiguration()
            
            if device.activeFormat.isVideoStabilizationModeSupported(.cinematic) {
                if let connection = movieOutput.connection(with: .video),
                   connection.isVideoStabilizationSupported {
                    connection.preferredVideoStabilizationMode = .cinematic
                }
            }
            
            if device.isFocusModeSupported(.continuousAutoFocus) {
                device.focusMode = .continuousAutoFocus
            }
            
            if device.isExposureModeSupported(.continuousAutoExposure) {
                device.exposureMode = .continuousAutoExposure
            }
            
            if device.isWhiteBalanceModeSupported(.continuousAutoWhiteBalance) {
                device.whiteBalanceMode = .continuousAutoWhiteBalance
            }
            
            device.unlockForConfiguration()
        } catch {
            print("Error optimizing video capture: \(error)")
        }
    }
    
    private func configureTintSettings() {
        guard let device = device else { return }
        
        do {
            try device.lockForConfiguration()
            if device.isWhiteBalanceModeSupported(.locked) {
                device.whiteBalanceMode = .locked
                
                let currentGains = device.deviceWhiteBalanceGains
                var newGains = currentGains
                let tintScale = currentTint / 150.0
                
                if tintScale > 0 {
                    newGains.greenGain = currentGains.greenGain * (1.0 + Float(tintScale))
                } else {
                    let magentaScale = 1.0 + Float(abs(tintScale))
                    newGains.redGain = currentGains.redGain * magentaScale
                    newGains.blueGain = currentGains.blueGain * magentaScale
                }
                
                let maxGain = device.maxWhiteBalanceGain
                newGains.redGain = min(max(1.0, newGains.redGain), maxGain)
                newGains.greenGain = min(max(1.0, newGains.greenGain), maxGain)
                newGains.blueGain = min(max(1.0, newGains.blueGain), maxGain)
                
                device.setWhiteBalanceModeLocked(with: newGains) { _ in }
            }
            device.unlockForConfiguration()
        } catch {
            print("Error setting tint: \(error.localizedDescription)")
            self.error = .whiteBalanceError
        }
    }
    
    func updateTint(_ newValue: Double) {
        currentTint = newValue.clamped(to: tintRange)
        configureTintSettings()
    }
    
    var shutterAngle: Double {
        get {
            let angle = Double(shutterSpeed.value) / Double(shutterSpeed.timescale) * selectedFrameRate * 360.0
            let clampedAngle = min(max(angle, 1.1), 360.0)
            
            return clampedAngle
        }
        set {
            let clampedAngle = min(max(newValue, 1.1), 360.0)
            let duration = (clampedAngle/360.0) * (1.0/selectedFrameRate)
            
            let time = CMTimeMakeWithSeconds(duration, preferredTimescale: 1000000)
            updateShutterSpeed(time)
            
            DispatchQueue.main.async {
                self.shutterSpeed = time
            }
        }
    }
    
    func updateShutterAngle(_ angle: Double) {
        self.shutterAngle = angle
    }
    
    private func updateExposureMode() {
        guard let device = device else { return }
        
        do {
            try device.lockForConfiguration()
            
            if isAutoExposureEnabled {
                if device.isExposureModeSupported(.continuousAutoExposure) {
                    device.exposureMode = .continuousAutoExposure
                    print("üì∑ Auto exposure enabled")
                }
            } else {
                if device.isExposureModeSupported(.custom) {
                    device.exposureMode = .custom
                    device.setExposureModeCustom(duration: device.exposureDuration,
                                                 iso: device.iso) { _ in }
                    print("üì∑ Manual exposure enabled")
                }
            }
            
            device.unlockForConfiguration()
        } catch {
            print("‚ùå Error setting exposure mode: \(error.localizedDescription)")
            self.error = .configurationFailed
        }
    }
    
    func processVideoFrame(_ sampleBuffer: CMSampleBuffer) -> CIImage? {
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return nil }
        var ciImage = CIImage(cvPixelBuffer: pixelBuffer)
        
        // Apply LUT if present
        if let lutFilter = lutManager.currentLUTFilter {
            lutFilter.setValue(ciImage, forKey: kCIInputImageKey)
            if let outputImage = lutFilter.outputImage {
                ciImage = outputImage
            }
        }
        
        return ciImage
    }
}

// MARK: - AVCaptureFileOutputRecordingDelegate
extension CameraViewModel: AVCaptureFileOutputRecordingDelegate {
    func fileOutput(_ output: AVCaptureFileOutput,
                    didStartRecordingTo fileURL: URL,
                    from connections: [AVCaptureConnection]) {
        print("Recording started successfully")
    }
    
    func fileOutput(_ output: AVCaptureFileOutput,
                    didFinishRecordingTo outputFileURL: URL,
                    from connections: [AVCaptureConnection],
                    error: Error?) {
        isRecording = false
        
        if let error = error {
            print("Recording failed: \(error.localizedDescription)")
            DispatchQueue.main.async {
                self.error = .recordingFailed
                self.isProcessingRecording = false
            }
            return
        }
        
        // Save to photo library
        PHPhotoLibrary.requestAuthorization { [weak self] status in
            guard status == .authorized else {
                DispatchQueue.main.async {
                    self?.error = .savingFailed
                    self?.isProcessingRecording = false
                    print("Photo library access denied")
                }
                return
            }
            
            PHPhotoLibrary.shared().performChanges({
                let options = PHAssetResourceCreationOptions()
                options.shouldMoveFile = true
                let creationRequest = PHAssetCreationRequest.forAsset()
                creationRequest.addResource(with: .video,
                                            fileURL: outputFileURL,
                                            options: options)
            }) { success, error in
                DispatchQueue.main.async {
                    if success {
                        print("Video saved to photo library")
                        self?.recordingFinished = true
                    } else {
                        print("Error saving video: \(String(describing: error))")
                        self?.error = .savingFailed
                    }
                    self?.isProcessingRecording = false
                }
            }
        }
    }
}

// MARK: - Orientation Helper
extension UIDeviceOrientation {
    var videoTransform: CGAffineTransform {
        switch self {
        case .landscapeRight:
            return CGAffineTransform(rotationAngle: CGFloat.pi)
        case .portraitUpsideDown:
            return CGAffineTransform(rotationAngle: -CGFloat.pi / 2)
        case .landscapeLeft:
            return .identity
        case .portrait:
            return CGAffineTransform(rotationAngle: CGFloat.pi / 2)
        case .unknown, .faceUp, .faceDown:
            return CGAffineTransform(rotationAngle: CGFloat.pi / 2)
        @unknown default:
            return CGAffineTransform(rotationAngle: CGFloat.pi / 2)
        }
    }
}

extension AVFrameRateRange {
    func containsFrameRate(_ fps: Double) -> Bool {
        return fps >= minFrameRate && fps <= maxFrameRate
    }
}

private extension Double {
    func clamped(to range: ClosedRange<Double>) -> Double {
        return min(max(self, range.lowerBound), range.upperBound)
    }
}

extension CameraError {
    static func configurationFailed(message: String = "Camera configuration failed") -> CameraError {
        return .custom(message: message)
    }
}

================
File: camera/Features/Camera/DocumentPicker.swift
================
import SwiftUI
import UniformTypeIdentifiers

struct DocumentPicker: UIViewControllerRepresentable {
    let types: [UTType]
    let onPick: (URL) -> Void
    
    func makeUIViewController(context: Context) -> UIDocumentPickerViewController {
        print("üìÑ DocumentPicker: Creating document picker for types: \(types.map { $0.identifier })")
        let picker = UIDocumentPickerViewController(forOpeningContentTypes: types)
        picker.delegate = context.coordinator
        picker.allowsMultipleSelection = false
        picker.shouldShowFileExtensions = true
        print("üìÑ DocumentPicker: Document picker created successfully")
        return picker
    }
    
    func updateUIViewController(_ uiViewController: UIDocumentPickerViewController, context: Context) {}
    
    func makeCoordinator() -> Coordinator {
        print("üìÑ DocumentPicker: Creating coordinator")
        return Coordinator(onPick: onPick)
    }
    
    class Coordinator: NSObject, UIDocumentPickerDelegate {
        let onPick: (URL) -> Void
        
        init(onPick: @escaping (URL) -> Void) {
            self.onPick = onPick
            super.init()
            print("üìÑ DocumentPicker: Coordinator initialized")
        }
        
        func documentPicker(_ controller: UIDocumentPickerViewController, didPickDocumentsAt urls: [URL]) {
            guard let url = urls.first else {
                print("‚ùå DocumentPicker: No document was selected")
                return
            }
            
            print("‚úÖ DocumentPicker: Document selected at URL: \(url.path)")
            
            if !url.startAccessingSecurityScopedResource() {
                print("‚ùå DocumentPicker: Failed to access security scoped resource at \(url.path)")
                return
            }
            
            defer {
                url.stopAccessingSecurityScopedResource()
                print("üìÑ DocumentPicker: Stopped accessing security scoped resource")
            }
            
            guard FileManager.default.fileExists(atPath: url.path) else {
                print("‚ùå DocumentPicker: File does not exist at path: \(url.path)")
                return
            }
            
            do {
                let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent(url.lastPathComponent)
                
                if FileManager.default.fileExists(atPath: tempURL.path) {
                    try FileManager.default.removeItem(at: tempURL)
                    print("üìÑ DocumentPicker: Removed existing file at temp location")
                }
                
                try FileManager.default.copyItem(at: url, to: tempURL)
                print("‚úÖ DocumentPicker: Successfully copied file to: \(tempURL.path)")
                
                let fileAttributes = try FileManager.default.attributesOfItem(atPath: tempURL.path)
                if let fileSize = fileAttributes[.size] as? NSNumber {
                    print("üìÑ DocumentPicker: File size: \(fileSize.intValue) bytes")
                }
                
                DispatchQueue.main.async {
                    self.onPick(tempURL)
                }
            } catch {
                print("‚ùå DocumentPicker: Error handling selected file: \(error.localizedDescription)")
            }
        }
        
        func documentPickerWasCancelled(_ controller: UIDocumentPickerViewController) {
            print("üìÑ DocumentPicker: Document selection was cancelled")
        }
    }
}

================
File: camera/Features/Camera/ShutterAngle.swift
================
import Foundation

enum ShutterAngle: Double, CaseIterable {
    case angle_360 = 360.0  // 1/24
    case angle_345_6 = 345.6  // 1/25
    case angle_288 = 288.0  // 1/30
    case angle_262_2 = 262.2  // 1/33
    case angle_180 = 180.0  // 1/48
    case angle_172_8 = 172.8  // 1/50
    case angle_144 = 144.0  // 1/60
    case angle_90 = 90.0   // 1/96
    case angle_86_4 = 86.4  // 1/100
    case angle_72 = 72.0   // 1/120
    case angle_69_1 = 69.1  // 1/125
    case angle_34_6 = 34.6  // 1/250
    case angle_17_3 = 17.3  // 1/500
    case angle_8_6 = 8.6   // 1/1000
    case angle_4_3 = 4.3   // 1/2000
    case angle_2_2 = 2.2   // 1/4000
    case angle_1_1 = 1.1   // 1/8000
    
    var shutterSpeed: String {
        switch self {
        case .angle_360: return "1/24"
        case .angle_345_6: return "1/25"
        case .angle_288: return "1/30"
        case .angle_262_2: return "1/33"
        case .angle_180: return "1/48"
        case .angle_172_8: return "1/50"
        case .angle_144: return "1/60"
        case .angle_90: return "1/96"
        case .angle_86_4: return "1/100"
        case .angle_72: return "1/120"
        case .angle_69_1: return "1/125"
        case .angle_34_6: return "1/250"
        case .angle_17_3: return "1/500"
        case .angle_8_6: return "1/1000"
        case .angle_4_3: return "1/2000"
        case .angle_2_2: return "1/4000"
        case .angle_1_1: return "1/8000"
        }
    }
}

================
File: camera/Features/Camera/VideoOutputDelegate.swift
================
import AVFoundation
import CoreImage

class VideoOutputDelegate: NSObject, AVCaptureVideoDataOutputSampleBufferDelegate {
    
    let lutManager: LUTManager
    let viewModel: CameraViewModel
    let context: CIContext
    
    // Counter to limit debug logging
    private static var frameCounter = 0
    
    init(lutManager: LUTManager, viewModel: CameraViewModel, context: CIContext) {
        self.lutManager = lutManager
        self.viewModel = viewModel
        self.context = context
        super.init()
        
        print("VideoOutputDelegate initialized")
    }
    
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        VideoOutputDelegate.frameCounter += 1
        
        // Only print debug logging every 60 frames to avoid console spam
        let isLoggingFrame = VideoOutputDelegate.frameCounter % 60 == 0
        // After 120 frames, only log important events
        let isEstablishedStream = VideoOutputDelegate.frameCounter > 120
        
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
            if isLoggingFrame && !isEstablishedStream {
                print("Could not get pixel buffer from sample buffer")
            }
            return
        }
        
        // Create CIImage from the pixel buffer
        var ciImage = CIImage(cvPixelBuffer: pixelBuffer)
        
        // If Apple Log is enabled, handle LOG processing
        if viewModel.isAppleLogEnabled {
            if isLoggingFrame && !isEstablishedStream {
                print("Processing LOG image")
            }
        }
        
        // Apply LUT if available
        if lutManager.currentLUTFilter != nil {
            if isLoggingFrame && !isEstablishedStream {
                print("Attempting to apply LUT filter")
            }
            
            if let processedImage = lutManager.applyLUT(to: ciImage) {
                ciImage = processedImage
                
                if isLoggingFrame && !isEstablishedStream {
                    print("‚úÖ LUT applied successfully")
                }
            } else if isLoggingFrame {
                print("‚ùå LUT application failed")
            }
        }
        
        // Render the processed image back to the pixel buffer
        context.render(ciImage, to: pixelBuffer)
        
        // Process the frame in the viewModel - just check if processing succeeded
        if viewModel.processVideoFrame(sampleBuffer) != nil {
            if isLoggingFrame && !isEstablishedStream {
                print("Frame processed successfully")
            }
        }
        
        // Shutter angle debug removed to reduce console spam
    }
}

================
File: camera/Features/LUT/CubeLUTLoader.swift
================
//
//  CubeLUTLoader.swift
//  camera
//
//  Created by spencer on 2024-12-30.
//

import Foundation
import CoreImage

/// Loads a .cube file and returns data for CIColorCube filter
class CubeLUTLoader {
    
    /// Parse .cube file into Float array and return dimension + LUT data
    static func loadCubeFile(name: String) throws -> (dimension: Int, data: [Float]) {
        guard let filePath = Bundle.main.url(forResource: name, withExtension: "cube") else {
            print("‚ùå CubeLUTLoader: LUT file '\(name).cube' not found in bundle")
            throw NSError(domain: "CubeLUTLoader", code: 1, userInfo: [NSLocalizedDescriptionKey: "LUT file not found"])
        }
        return try loadCubeFile(from: filePath)
    }
    
    /// Parse .cube file into Float array and return dimension + LUT data
    static func loadCubeFile(from url: URL) throws -> (dimension: Int, data: [Float]) {
        print("\nüîÑ CubeLUTLoader: Loading LUT from \(url.path)")
        
        // First check if URL can be accessed (file might be security-scoped)
        if !FileManager.default.fileExists(atPath: url.path) {
            print("‚ùå CubeLUTLoader: File doesn't exist at path: \(url.path)")
            throw NSError(domain: "CubeLUTLoader", code: 5, userInfo: [
                NSLocalizedDescriptionKey: "LUT file not found at specified path"
            ])
        }
        
        // Start accessing security-scoped resource if needed
        var didStartAccess = false
        if url.startAccessingSecurityScopedResource() {
            didStartAccess = true
            print("‚úÖ CubeLUTLoader: Started accessing security-scoped resource")
        }
        
        // Make sure we stop accessing the resource when we're done
        defer {
            if didStartAccess {
                url.stopAccessingSecurityScopedResource()
                print("‚úÖ CubeLUTLoader: Stopped accessing security-scoped resource")
            }
        }
        
        // Validate file exists and is readable
        try validateLUTFile(at: url)
        
        let fileContents: String
        do {
            fileContents = try String(contentsOf: url, encoding: .utf8)
            print("‚úÖ Read \(fileContents.count) characters from LUT file")
            
            // Print first few lines of the file for debugging
            let previewLines = fileContents.components(separatedBy: .newlines).prefix(5).joined(separator: "\n")
            print("üìÉ LUT File Preview (first 5 lines):\n\(previewLines)")
        } catch {
            print("‚ùå Failed to read LUT file: \(error.localizedDescription)")
            if let nsError = error as NSError? {
                print("‚ùå Error details - Domain: \(nsError.domain), Code: \(nsError.code)")
                for (key, value) in nsError.userInfo {
                    print("‚ùå UserInfo[\(key)] = \(value)")
                }
            }
            
            // Try alternate approach for binary files
            if (try? url.resourceValues(forKeys: [.contentTypeKey]))?.contentType?.conforms(to: .data) == true {
                print("‚ö†Ô∏è File appears to be binary data, attempting alternate loading method")
                throw NSError(domain: "CubeLUTLoader", code: 3, userInfo: [
                    NSLocalizedDescriptionKey: "Binary .cube files are not yet supported",
                    NSUnderlyingErrorKey: error
                ])
            }
            
            throw NSError(domain: "CubeLUTLoader", code: 3, userInfo: [
                NSLocalizedDescriptionKey: "Failed to read LUT file: \(error.localizedDescription)",
                NSUnderlyingErrorKey: error
            ])
        }
        
        let lines = fileContents.components(separatedBy: .newlines)
        print("üìù Parsing \(lines.count) lines from LUT file")
        
        var dimension = 0
        var cubeData = [Float]()
        var foundSize = false
        var headerEnded = false
        var linesProcessed = 0
        var dataLinesProcessed = 0
        var headerLines: [String] = []
        
        for line in lines {
            linesProcessed += 1
            let trimmed = line.trimmingCharacters(in: .whitespacesAndNewlines)
            
            // Skip comments and empty lines
            if trimmed.hasPrefix("#") || trimmed.isEmpty {
                if !headerEnded && !trimmed.isEmpty {
                    headerLines.append(trimmed)
                }
                continue
            }
            
            // Process LUT size
            if trimmed.lowercased().contains("lut_3d_size") {
                let parts = trimmed.components(separatedBy: CharacterSet.whitespaces)
                if let sizeString = parts.last, let size = Int(sizeString) {
                    dimension = size
                    let totalCount = size * size * size * 3
                    cubeData.reserveCapacity(totalCount)
                    foundSize = true
                    print("‚úÖ Found LUT_3D_SIZE: \(size), expecting \(totalCount) data points")
                    headerLines.append(trimmed)
                } else {
                    print("‚ö†Ô∏è Found LUT_3D_SIZE but couldn't parse value: \(trimmed)")
                }
            } 
            // Process data lines
            else if dimension > 0 {
                if !headerEnded {
                    headerEnded = true
                    print("üìã LUT Header:\n\(headerLines.joined(separator: "\n"))")
                }
                
                // Parse RGB values on this line
                let components = trimmed.components(separatedBy: CharacterSet.whitespaces)
                    .filter { !$0.isEmpty }
                    .compactMap { Float($0) }
                
                if components.count == 3 {
                    cubeData.append(contentsOf: components)
                    dataLinesProcessed += 1
                    
                    // Print the first few data points for debugging
                    if dataLinesProcessed <= 3 {
                        print("üìä Data Line \(dataLinesProcessed): \(components)")
                    }
                } else if !trimmed.isEmpty {
                    print("‚ö†Ô∏è Line \(linesProcessed): Invalid data format - expected 3 values, got \(components.count): \(trimmed)")
                }
            }
        }
        
        let expectedDataLines = dimension * dimension * dimension
        print("üìä LUT Stats: Processed \(dataLinesProcessed) data lines out of expected \(expectedDataLines)")
        print("üìä Parsed \(cubeData.count) values, expected \(dimension * dimension * dimension * 3)")
        
        if dimension == 0 || !foundSize {
            print("‚ùå Missing LUT_3D_SIZE in file")
            throw NSError(domain: "CubeLUTLoader", code: 2, userInfo: [NSLocalizedDescriptionKey: "Invalid .cube file - Missing LUT_3D_SIZE"])
        }
        
        if cubeData.isEmpty {
            print("‚ùå No valid data found in LUT file")
            throw NSError(domain: "CubeLUTLoader", code: 2, userInfo: [NSLocalizedDescriptionKey: "Invalid or empty .cube file - No data found"])
        }
        
        // If we have at least some data but not the complete amount, warn but continue
        let expectedDataCount = dimension * dimension * dimension * 3
        if cubeData.count < expectedDataCount {
            print("‚ö†Ô∏è Incomplete LUT data: Found \(cubeData.count) values, expected \(expectedDataCount)")
            
            // If we're significantly short, throw an error
            if cubeData.count < expectedDataCount / 2 {
                print("‚ùå Insufficient LUT data: Found \(cubeData.count) values, expected \(expectedDataCount)")
                throw NSError(domain: "CubeLUTLoader", code: 4, userInfo: [
                    NSLocalizedDescriptionKey: "Incomplete LUT data: Only \(cubeData.count)/\(expectedDataCount) values found"
                ])
            }
            
            // For minor shortfalls, pad with zeros to maintain expected dimensions
            let shortfall = expectedDataCount - cubeData.count
            if shortfall > 0 && shortfall < expectedDataCount / 10 {  // Less than 10% missing
                print("‚ö†Ô∏è Padding \(shortfall) missing values with zeros")
                cubeData.append(contentsOf: Array(repeating: 0.0, count: shortfall))
            }
        }
        
        // Validate values are in reasonable range (0.0-1.0)
        let outOfRangeValues = cubeData.filter { $0 < 0.0 || $0 > 1.0 }
        if !outOfRangeValues.isEmpty {
            print("‚ö†Ô∏è Found \(outOfRangeValues.count) values outside the expected 0.0-1.0 range")
            print("‚ö†Ô∏è Example out-of-range values: \(outOfRangeValues.prefix(5))")
            
            // Clamp values to valid range
            for i in 0..<cubeData.count {
                cubeData[i] = max(0.0, min(1.0, cubeData[i]))
            }
            print("‚úÖ Clamped all values to 0.0-1.0 range for compatibility")
        }
        
        print("‚úÖ Successfully parsed LUT file with dimension \(dimension) and \(cubeData.count) values")
        return (dimension, cubeData)
    }
    
    /// Validates that a LUT file exists and is readable
    static func validateLUTFile(at url: URL) throws {
        print("üîç Validating LUT file at \(url.path)")
        
        // Check if the file exists
        let fileManager = FileManager.default
        guard fileManager.fileExists(atPath: url.path) else {
            print("‚ùå LUT file does not exist at \(url.path)")
            throw NSError(domain: "CubeLUTLoader", code: 5, userInfo: [
                NSLocalizedDescriptionKey: "LUT file does not exist at path"
            ])
        }
        
        // Check if file is readable
        do {
            let resourceValues = try url.resourceValues(forKeys: [.isReadableKey, .fileSizeKey, .contentTypeKey])
            guard resourceValues.isReadable == true else {
                print("‚ùå LUT file is not readable")
                throw NSError(domain: "CubeLUTLoader", code: 6, userInfo: [
                    NSLocalizedDescriptionKey: "LUT file is not readable"
                ])
            }
            
            if let fileSize = resourceValues.fileSize {
                print("‚úÖ LUT file size: \(fileSize) bytes")
                if fileSize == 0 {
                    print("‚ùå LUT file is empty (0 bytes)")
                    throw NSError(domain: "CubeLUTLoader", code: 7, userInfo: [
                        NSLocalizedDescriptionKey: "LUT file is empty"
                    ])
                }
            }
            
            if let contentType = resourceValues.contentType {
                print("‚úÖ LUT file content type: \(contentType.identifier)")
            }
        } catch {
            print("‚ùå Failed to get resource values: \(error.localizedDescription)")
            throw NSError(domain: "CubeLUTLoader", code: 8, userInfo: [
                NSLocalizedDescriptionKey: "Failed to read LUT file properties",
                NSUnderlyingErrorKey: error
            ])
        }
        
        // Attempt to check file permissions
        do {
            let attributes = try fileManager.attributesOfItem(atPath: url.path)
            if let permissions = attributes[.posixPermissions] as? NSNumber {
                print("‚úÖ LUT file permissions: \(String(format: "%o", permissions.intValue))")
            }
        } catch {
            print("‚ö†Ô∏è Could not read file attributes: \(error.localizedDescription)")
        }
        
        print("‚úÖ LUT file validation passed")
    }
}

================
File: camera/Features/LUT/LUTManager.swift
================
import SwiftUI
import CoreImage
import UniformTypeIdentifiers

class LUTManager: ObservableObject {
    
    @Published var currentLUTFilter: CIFilter?
    private var dimension: Int = 0
    @Published var selectedLUTURL: URL?
    @Published var recentLUTs: [String: URL]? = [:]
    
    // Maximum number of recent LUTs to store
    private let maxRecentLUTs = 5
    
    // UserDefaults key for storing recent LUTs
    private let recentLUTsKey = "recentLUTs"
    
    // New properties to store cube data
    private var cubeDimension: Int = 0
    private var cubeData: Data?
    
    // Supported file types
    static let supportedTypes = [UTType.data]
    
    init() {
        loadRecentLUTs()
    }
    
    func loadLUT(named fileName: String) {
        print("üîç LUTManager: Attempting to load LUT file named '\(fileName)'")
        do {
            guard let fileURL = Bundle.main.url(forResource: fileName, withExtension: "cube") else {
                print("‚ùå LUTManager Error: File '\(fileName).cube' not found in bundle")
                print("üìÇ Bundle path: \(Bundle.main.bundlePath)")
                print("üìÇ Available resources: \(Bundle.main.paths(forResourcesOfType: "cube", inDirectory: nil))")
                throw NSError(domain: "LUTManager", code: 1, userInfo: [NSLocalizedDescriptionKey: "LUT file not found in bundle"])
            }
            
            print("‚úÖ LUT file found at: \(fileURL.path)")
            let lutInfo = try CubeLUTLoader.loadCubeFile(name: fileName)
            print("‚úÖ LUT data loaded: dimension=\(lutInfo.dimension), data.count=\(lutInfo.data.count)")
            setupLUTFilter(lutInfo: lutInfo)
            addToRecentLUTs(url: fileURL)
            print("‚úÖ LUT successfully loaded and configured")
        } catch {
            print("‚ùå LUTManager Error: Failed to load LUT '\(fileName)': \(error.localizedDescription)")
        }
    }
    
    func loadLUT(from url: URL) {
        print("\nüìä LUTManager: Attempting to load LUT from URL: \(url.path)")
        print("üìä LUTManager: URL is file URL: \(url.isFileURL)")
        print("üìä LUTManager: File exists: \(FileManager.default.fileExists(atPath: url.path))")
        
        do {
            let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
            if let fileSize = attributes[.size] as? NSNumber {
                print("üìä LUTManager: File size: \(fileSize.intValue) bytes")
            }
            if let fileType = attributes[.type] as? String {
                print("üìä LUTManager: File type: \(fileType)")
            }
        } catch {
            print("‚ùå LUTManager Error: Could not read file attributes: \(error.localizedDescription)")
        }
        
        do {
            let handle = try FileHandle(forReadingFrom: url)
            defer { try? handle.close() }
            if let data = try handle.readToEnd(), let preview = String(data: data.prefix(100), encoding: .utf8) {
                print("üìä LUTManager: File content preview: \(preview.prefix(50))")
            } else {
                print("üìä LUTManager: Could not read file content preview (may be binary data)")
            }
        } catch {
            print("‚ùå LUTManager Error: Failed to read file content: \(error.localizedDescription)")
        }
        
        do {
            let lutInfo = try CubeLUTLoader.loadCubeFile(from: url)
            print("‚úÖ LUT data loaded from URL: dimension=\(lutInfo.dimension), data.count=\(lutInfo.data.count)")
            setupLUTFilter(lutInfo: lutInfo)
            addToRecentLUTs(url: url)
            selectedLUTURL = url
            print("‚úÖ LUT successfully loaded and configured from URL")
        } catch {
            print("‚ùå LUTManager Error: Failed to load LUT from URL: \(error.localizedDescription)")
        }
    }
    
    // Sets up the CIColorCube filter with the provided LUT information
    func setupLUTFilter(lutInfo: (dimension: Int, data: [Float])) {
        self.cubeDimension = lutInfo.dimension
        self.dimension = lutInfo.dimension
        let expectedCount = lutInfo.dimension * lutInfo.dimension * lutInfo.dimension * 4 // RGBA
        
        // Convert RGB data to RGBA (required by CIFilter)
        var rgbaData = [Float]()
        rgbaData.reserveCapacity(expectedCount)
        
        // Original data is in RGB format, we need to add alpha = 1.0 for each entry
        for i in stride(from: 0, to: lutInfo.data.count, by: 3) {
            if i + 2 < lutInfo.data.count {
                rgbaData.append(lutInfo.data[i])     // R
                rgbaData.append(lutInfo.data[i+1])   // G
                rgbaData.append(lutInfo.data[i+2])   // B
                rgbaData.append(1.0)                 // A (always 1.0)
            }
        }
        
        // Create a copy of the data and convert to NSData
        // Fix for the dangling buffer pointer issue
        var dataCopy = rgbaData
        let nsData = NSData(bytes: &dataCopy, length: dataCopy.count * MemoryLayout<Float>.size)
        self.cubeData = nsData as Data
        
        if let filter = CIFilter(name: "CIColorCube") {
            filter.setValue(lutInfo.dimension, forKey: "inputCubeDimension")
            filter.setValue(self.cubeData, forKey: "inputCubeData")
            self.currentLUTFilter = filter
            print("‚úÖ LUT filter created: dimension=\(lutInfo.dimension), data size=\(self.cubeData?.count ?? 0) bytes")
        } else {
            print("‚ùå Failed to create CIColorCube filter")
        }
    }
    
    // Applies the LUT to the given CIImage using a freshly created filter instance
    func applyLUT(to image: CIImage) -> CIImage? {
        guard let cubeData = self.cubeData else { return nil }
        
        let params = [
            "inputCubeDimension": cubeDimension,
            "inputCubeData": cubeData,
            "inputColorSpace": CGColorSpace(name: CGColorSpace.sRGB), // Explicit color space
            kCIInputImageKey: image
        ] as [String : Any]
        
        return CIFilter(name: "CIColorCube", parameters: params)?.outputImage
    }
    
    // Creates a basic programmatic LUT when no files are available
    func setupProgrammaticLUT(dimension: Int, data: [Float]) {
        print("üé® Creating programmatic LUT: dimension=\(dimension), points=\(data.count/3)")
        
        var rgbaData = [Float]()
        rgbaData.reserveCapacity(dimension * dimension * dimension * 4)
        
        // Convert RGB data to RGBA (required by CIFilter)
        for i in stride(from: 0, to: data.count, by: 3) {
            if i + 2 < data.count {
                rgbaData.append(data[i])     // R
                rgbaData.append(data[i+1])   // G
                rgbaData.append(data[i+2])   // B
                rgbaData.append(1.0)         // A (always 1.0)
            }
        }
        
        // Create a copy of the data to avoid dangling pointer
        var dataCopy = rgbaData
        let nsData = NSData(bytes: &dataCopy, length: dataCopy.count * MemoryLayout<Float>.size)
        self.cubeData = nsData as Data
        self.cubeDimension = dimension
        
        if let filter = CIFilter(name: "CIColorCube") {
            filter.setValue(dimension, forKey: "inputCubeDimension")
            filter.setValue(self.cubeData, forKey: "inputCubeData")
            self.currentLUTFilter = filter
            print("‚úÖ Programmatic LUT filter created")
        } else {
            print("‚ùå Failed to create programmatic CIColorCube filter")
        }
    }
    
    // MARK: - Recent LUT Management
    
    private func loadRecentLUTs() {
        if let recentDict = UserDefaults.standard.dictionary(forKey: recentLUTsKey) as? [String: String] {
            var loadedLUTs: [String: URL] = [:]
            
            for (name, urlString) in recentDict {
                if let url = URL(string: urlString) {
                    loadedLUTs[name] = url
                }
            }
            
            self.recentLUTs = loadedLUTs
        }
    }
    
    private func addToRecentLUTs(url: URL) {
        if recentLUTs == nil {
            recentLUTs = [:]
        }
        
        // Add or update the URL
        recentLUTs?[url.lastPathComponent] = url
        
        // Ensure we don't exceed the maximum number of recent LUTs
        if let count = recentLUTs?.count, count > maxRecentLUTs {
            // Remove oldest entries
            let sortedKeys = recentLUTs?.keys.sorted { lhs, rhs in
                if let lhsURL = recentLUTs?[lhs], let rhsURL = recentLUTs?[rhs] {
                    return (try? lhsURL.resourceValues(forKeys: [.contentModificationDateKey]).contentModificationDate) ?? Date() >
                           (try? rhsURL.resourceValues(forKeys: [.contentModificationDateKey]).contentModificationDate) ?? Date()
                }
                return false
            }
            
            if let keysToRemove = sortedKeys?.suffix(from: maxRecentLUTs) {
                for key in keysToRemove {
                    recentLUTs?.removeValue(forKey: key)
                }
            }
        }
        
        // Save to UserDefaults
        let urlDict = recentLUTs?.mapValues { $0.absoluteString }
        UserDefaults.standard.set(urlDict, forKey: recentLUTsKey)
    }
    
    // MARK: - LUT Management
    
    /// Clears the current LUT filter
    func clearLUT() {
        currentLUTFilter = nil
        selectedLUTURL = nil
        print("‚úÖ LUT filter cleared")
    }
}

================
File: camera/Features/Settings/SettingsModel.swift
================
import Foundation
import AVFoundation
import CoreMedia

class SettingsModel: ObservableObject {
    @Published var isAppleLogEnabled: Bool {
        didSet {
            UserDefaults.standard.set(isAppleLogEnabled, forKey: "isAppleLogEnabled")
            NotificationCenter.default.post(name: .appleLogSettingChanged, object: nil)
        }
    }
    
    var isAppleLogSupported: Bool {
        guard let device = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
            return false
        }
        
        // Check if any format supports Apple Log
        return device.formats.contains { format in
            let colorSpaces = format.supportedColorSpaces.map { $0.rawValue }
            return colorSpaces.contains(AVCaptureColorSpace.appleLog.rawValue)
        }
    }
    
    init() {
        self.isAppleLogEnabled = UserDefaults.standard.bool(forKey: "isAppleLogEnabled")
    }
}

extension Notification.Name {
    static let appleLogSettingChanged = Notification.Name("appleLogSettingChanged")
}

================
File: camera/Features/Settings/SettingsView.swift
================
import SwiftUI
import UniformTypeIdentifiers

struct SettingsView: View {
    @Environment(\.dismiss) private var dismiss
    @ObservedObject var lutManager: LUTManager
    @StateObject private var documentDelegate: LUTDocumentPickerDelegate
    @State private var showLUTHistory = false
    
    init(lutManager: LUTManager) {
        self.lutManager = lutManager
        // Initialize the document delegate with the LUT manager
        _documentDelegate = StateObject(wrappedValue: LUTDocumentPickerDelegate(lutManager: lutManager))
    }
    
    var body: some View {
        NavigationView {
            Form {
                Section(header: Text("Camera Settings")) {
                    // Other settings can go here
                }
                
                Section {
                    // Current LUT display
                    if let selectedLUT = lutManager.selectedLUTURL?.lastPathComponent {
                        HStack {
                            Label {
                                Text("Current LUT")
                            } icon: {
                                Image(systemName: "photo.artframe")
                            }
                            .foregroundColor(.primary)
                            
                            Spacer()
                            
                            Text(selectedLUT)
                                .foregroundColor(.secondary)
                                .lineLimit(1)
                                .truncationMode(.middle)
                        }
                    }
                    
                    // Clear button
                    Button(action: {
                        lutManager.currentLUTFilter = nil
                        lutManager.selectedLUTURL = nil
                    }) {
                        Label("Clear LUT", systemImage: "trash")
                    }
                    .foregroundColor(.red)
                    
                    // Import button
                    Button(action: importLUT) {
                        Label("Import LUT", systemImage: "square.and.arrow.down")
                    }
                    
                    // Recent LUTs
                    if let recent = lutManager.recentLUTs, !recent.isEmpty {
                        DisclosureGroup("Recently Used LUTs") {
                            ForEach(Array(recent.keys), id: \.self) { key in
                                if let url = recent[key] {
                                    Button(action: {
                                        lutManager.loadLUT(from: url)
                                    }) {
                                        Text(key)
                                            .foregroundColor(.blue)
                                    }
                                }
                            }
                        }
                    }
                } header: {
                    Text("LUT Management")
                }
                
                Section(header: Text("LUT Info"), footer: Text("LUTs are applied after LOG conversion to ensure proper display")) {
                    Text("Supported formats: .cube, .3dl")
                        .font(.footnote)
                        .foregroundColor(.secondary)
                }
            }
            .navigationTitle("Settings")
            .navigationBarItems(trailing: Button("Done") {
                dismiss()
            })
        }
    }
    
    private func showDocumentPicker() {
        let picker = UIDocumentPickerViewController(
            forOpeningContentTypes: LUTManager.supportedTypes,
            asCopy: true
        )
        picker.delegate = documentDelegate
        
        if let windowScene = UIApplication.shared.connectedScenes.first as? UIWindowScene,
           let window = windowScene.windows.first,
           let rootViewController = window.rootViewController {
            rootViewController.present(picker, animated: true)
        }
    }
    
    private func importLUT() {
        showDocumentPicker()
    }
}

// Document picker delegate as a separate class
class LUTDocumentPickerDelegate: NSObject, UIDocumentPickerDelegate, ObservableObject {
    let lutManager: LUTManager
    
    init(lutManager: LUTManager) {
        self.lutManager = lutManager
        super.init()
        print("üìÑ LUTDocumentPickerDelegate: Initialized with LUTManager")
    }
    
    func documentPicker(_ controller: UIDocumentPickerViewController, didPickDocumentsAt urls: [URL]) {
        guard let selectedURL = urls.first else {
            print("‚ùå LUTDocumentPickerDelegate: No document was selected")
            return
        }
        
        print("‚úÖ LUTDocumentPickerDelegate: Document selected at URL: \(selectedURL.path)")
        
        // Start accessing the security-scoped resource
        let securityScopedAccess = selectedURL.startAccessingSecurityScopedResource()
        if !securityScopedAccess {
            print("‚ùå LUTDocumentPickerDelegate: Failed to access security scoped resource at \(selectedURL.path)")
        } else {
            print("‚úÖ LUTDocumentPickerDelegate: Successfully accessed security scoped resource")
        }
        
        // Make sure we stop accessing the resource when we're done
        defer {
            if securityScopedAccess {
                selectedURL.stopAccessingSecurityScopedResource()
                print("üìÑ LUTDocumentPickerDelegate: Stopped accessing security scoped resource")
            }
        }
        
        // Check if file exists
        guard FileManager.default.fileExists(atPath: selectedURL.path) else {
            print("‚ùå LUTDocumentPickerDelegate: File does not exist at path: \(selectedURL.path)")
            return
        }
        
        // Due to the issue with creating copies, we'll create a bookmark to the file instead
        // This allows the app to access the file later without needing to copy it
        do {
            let bookmarkData = try selectedURL.bookmarkData(options: .minimalBookmark, 
                                                  includingResourceValuesForKeys: nil, 
                                                  relativeTo: nil)
            
            // Use the bookmark to create a URL that we can use later
            var isStale = false
            let _ = try URL(resolvingBookmarkData: bookmarkData, 
                           options: .withoutUI, 
                           relativeTo: nil, 
                           bookmarkDataIsStale: &isStale)
            
            if isStale {
                print("‚ö†Ô∏è LUTDocumentPickerDelegate: Bookmark is stale, creating a new one")
                // You might want to recreate the bookmark here if needed
            }
            
            print("‚úÖ LUTDocumentPickerDelegate: Created bookmark for file")
            
            // Check if file is readable
            try checkFileIsReadable(at: selectedURL)
            
            // Pass the URL directly to LUTManager on the main thread
            DispatchQueue.main.async {
                self.lutManager.loadLUT(from: selectedURL)
            }
        } catch {
            print("‚ùå LUTDocumentPickerDelegate: Error handling selected file: \(error.localizedDescription)")
            if let nsError = error as NSError? {
                print("‚ùå Error details - Domain: \(nsError.domain), Code: \(nsError.code)")
                
                // If this is related to bookmark creation, try a fallback approach
                if nsError.domain == NSCocoaErrorDomain && nsError.code == 260 {
                    print("‚ö†Ô∏è LUTDocumentPickerDelegate: Trying fallback approach for file access")
                    
                    // Pass the URL directly to LUTManager as a fallback
                    DispatchQueue.main.async {
                        self.lutManager.loadLUT(from: selectedURL)
                    }
                }
            }
        }
    }
    
    func documentPickerWasCancelled(_ controller: UIDocumentPickerViewController) {
        print("üìÑ LUTDocumentPickerDelegate: Document selection was cancelled")
    }
    
    private func checkFileIsReadable(at url: URL) throws {
        print("üîç LUTDocumentPickerDelegate: Checking if file is readable: \(url.path)")
        
        // Check if we can open the file for reading
        let fileHandle = try FileHandle(forReadingFrom: url)
        defer {
            try? fileHandle.close()
        }
        
        // Try to read a small chunk of data
        if let data = try fileHandle.read(upToCount: 100), !data.isEmpty {
            print("‚úÖ LUTDocumentPickerDelegate: File is readable, read \(data.count) bytes")
            
            // If it's a text file, print a preview
            if let textPreview = String(data: data, encoding: .utf8) {
                print("üìÑ Content preview: \(textPreview.prefix(50))")
            } else {
                print("üìÑ File contains binary data (not UTF-8 text)")
            }
        } else {
            print("‚ö†Ô∏è LUTDocumentPickerDelegate: File is empty or unreadable")
            throw NSError(domain: "LUTDocumentPicker", code: 1, userInfo: [
                NSLocalizedDescriptionKey: "File is empty or could not be read"
            ])
        }
    }
}

#Preview {
    SettingsView(lutManager: LUTManager())
}

================
File: camera/Preview Content/Preview Assets.xcassets/Contents.json
================
{
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}

================
File: camera/Resources/TestLUT.cube
================
# Test LUT file
# This is a simple identity LUT (no color change)
# Created for testing the LUT loading functionality

LUT_3D_SIZE 8

# Data points (R G B)
0.0 0.0 0.0
0.0 0.0 0.142857
0.0 0.0 0.285714
0.0 0.0 0.428571
0.0 0.0 0.571429
0.0 0.0 0.714286
0.0 0.0 0.857143
0.0 0.0 1.0
0.0 0.142857 0.0
0.0 0.142857 0.142857
0.0 0.142857 0.285714
0.0 0.142857 0.428571
0.0 0.142857 0.571429
0.0 0.142857 0.714286
0.0 0.142857 0.857143
0.0 0.142857 1.0
0.0 0.285714 0.0
0.0 0.285714 0.142857
0.0 0.285714 0.285714
0.0 0.285714 0.428571
0.0 0.285714 0.571429
0.0 0.285714 0.714286
0.0 0.285714 0.857143
0.0 0.285714 1.0
0.0 0.428571 0.0
0.0 0.428571 0.142857
0.0 0.428571 0.285714
0.0 0.428571 0.428571
0.0 0.428571 0.571429
0.0 0.428571 0.714286
0.0 0.428571 0.857143
0.0 0.428571 1.0
0.0 0.571429 0.0
0.0 0.571429 0.142857
0.0 0.571429 0.285714
0.0 0.571429 0.428571
0.0 0.571429 0.571429
0.0 0.571429 0.714286
0.0 0.571429 0.857143
0.0 0.571429 1.0
0.0 0.714286 0.0
0.0 0.714286 0.142857
0.0 0.714286 0.285714
0.0 0.714286 0.428571
0.0 0.714286 0.571429
0.0 0.714286 0.714286
0.0 0.714286 0.857143
0.0 0.714286 1.0
0.0 0.857143 0.0
0.0 0.857143 0.142857
0.0 0.857143 0.285714
0.0 0.857143 0.428571
0.0 0.857143 0.571429
0.0 0.857143 0.714286
0.0 0.857143 0.857143
0.0 0.857143 1.0
0.0 1.0 0.0
0.0 1.0 0.142857
0.0 1.0 0.285714
0.0 1.0 0.428571
0.0 1.0 0.571429
0.0 1.0 0.714286
0.0 1.0 0.857143
0.0 1.0 1.0
0.142857 0.0 0.0
0.142857 0.0 0.142857
0.142857 0.0 0.285714
0.142857 0.0 0.428571
0.142857 0.0 0.571429
0.142857 0.0 0.714286
0.142857 0.0 0.857143
0.142857 0.0 1.0
0.142857 0.142857 0.0
0.142857 0.142857 0.142857
0.142857 0.142857 0.285714
0.142857 0.142857 0.428571
0.142857 0.142857 0.571429
0.142857 0.142857 0.714286
0.142857 0.142857 0.857143
0.142857 0.142857 1.0
0.142857 0.285714 0.0
0.142857 0.285714 0.142857
0.142857 0.285714 0.285714
0.142857 0.285714 0.428571
0.142857 0.285714 0.571429
0.142857 0.285714 0.714286
0.142857 0.285714 0.857143
0.142857 0.285714 1.0
0.142857 0.428571 0.0
0.142857 0.428571 0.142857
0.142857 0.428571 0.285714
0.142857 0.428571 0.428571
0.142857 0.428571 0.571429
0.142857 0.428571 0.714286
0.142857 0.428571 0.857143
0.142857 0.428571 1.0
0.142857 0.571429 0.0
0.142857 0.571429 0.142857
0.142857 0.571429 0.285714
0.142857 0.571429 0.428571
0.142857 0.571429 0.571429
0.142857 0.571429 0.714286
0.142857 0.571429 0.857143
0.142857 0.571429 1.0
0.142857 0.714286 0.0
0.142857 0.714286 0.142857
0.142857 0.714286 0.285714
0.142857 0.714286 0.428571
0.142857 0.714286 0.571429
0.142857 0.714286 0.714286
0.142857 0.714286 0.857143
0.142857 0.714286 1.0
0.142857 0.857143 0.0
0.142857 0.857143 0.142857
0.142857 0.857143 0.285714
0.142857 0.857143 0.428571
0.142857 0.857143 0.571429
0.142857 0.857143 0.714286
0.142857 0.857143 0.857143
0.142857 0.857143 1.0
0.142857 1.0 0.0
0.142857 1.0 0.142857
0.142857 1.0 0.285714
0.142857 1.0 0.428571
0.142857 1.0 0.571429
0.142857 1.0 0.714286
0.142857 1.0 0.857143
0.142857 1.0 1.0
0.285714 0.0 0.0
0.285714 0.0 0.142857
0.285714 0.0 0.285714
0.285714 0.0 0.428571
0.285714 0.0 0.571429
0.285714 0.0 0.714286
0.285714 0.0 0.857143
0.285714 0.0 1.0
0.285714 0.142857 0.0
0.285714 0.142857 0.142857
0.285714 0.142857 0.285714
0.285714 0.142857 0.428571
0.285714 0.142857 0.571429
0.285714 0.142857 0.714286
0.285714 0.142857 0.857143
0.285714 0.142857 1.0
0.285714 0.285714 0.0
0.285714 0.285714 0.142857
0.285714 0.285714 0.285714
0.285714 0.285714 0.428571
0.285714 0.285714 0.571429
0.285714 0.285714 0.714286
0.285714 0.285714 0.857143
0.285714 0.285714 1.0
0.285714 0.428571 0.0
0.285714 0.428571 0.142857
0.285714 0.428571 0.285714
0.285714 0.428571 0.428571
0.285714 0.428571 0.571429
0.285714 0.428571 0.714286
0.285714 0.428571 0.857143
0.285714 0.428571 1.0
0.285714 0.571429 0.0
0.285714 0.571429 0.142857
0.285714 0.571429 0.285714
0.285714 0.571429 0.428571
0.285714 0.571429 0.571429
0.285714 0.571429 0.714286
0.285714 0.571429 0.857143
0.285714 0.571429 1.0
0.285714 0.714286 0.0
0.285714 0.714286 0.142857
0.285714 0.714286 0.285714
0.285714 0.714286 0.428571
0.285714 0.714286 0.571429
0.285714 0.714286 0.714286
0.285714 0.714286 0.857143
0.285714 0.714286 1.0
0.285714 0.857143 0.0
0.285714 0.857143 0.142857
0.285714 0.857143 0.285714
0.285714 0.857143 0.428571
0.285714 0.857143 0.571429
0.285714 0.857143 0.714286
0.285714 0.857143 0.857143
0.285714 0.857143 1.0
0.285714 1.0 0.0
0.285714 1.0 0.142857
0.285714 1.0 0.285714
0.285714 1.0 0.428571
0.285714 1.0 0.571429
0.285714 1.0 0.714286
0.285714 1.0 0.857143
0.285714 1.0 1.0
0.428571 0.0 0.0
0.428571 0.0 0.142857
0.428571 0.0 0.285714
0.428571 0.0 0.428571
0.428571 0.0 0.571429
0.428571 0.0 0.714286
0.428571 0.0 0.857143
0.428571 0.0 1.0
0.428571 0.142857 0.0
0.428571 0.142857 0.142857
0.428571 0.142857 0.285714
0.428571 0.142857 0.428571
0.428571 0.142857 0.571429
0.428571 0.142857 0.714286
0.428571 0.142857 0.857143
0.428571 0.142857 1.0
0.428571 0.285714 0.0
0.428571 0.285714 0.142857
0.428571 0.285714 0.285714
0.428571 0.285714 0.428571
0.428571 0.285714 0.571429
0.428571 0.285714 0.714286
0.428571 0.285714 0.857143
0.428571 0.285714 1.0
0.428571 0.428571 0.0
0.428571 0.428571 0.142857
0.428571 0.428571 0.285714
0.428571 0.428571 0.428571
0.428571 0.428571 0.571429
0.428571 0.428571 0.714286
0.428571 0.428571 0.857143
0.428571 0.428571 1.0
0.428571 0.571429 0.0
0.428571 0.571429 0.142857
0.428571 0.571429 0.285714
0.428571 0.571429 0.428571
0.428571 0.571429 0.571429
0.428571 0.571429 0.714286
0.428571 0.571429 0.857143
0.428571 0.571429 1.0
0.428571 0.714286 0.0
0.428571 0.714286 0.142857
0.428571 0.714286 0.285714
0.428571 0.714286 0.428571
0.428571 0.714286 0.571429
0.428571 0.714286 0.714286
0.428571 0.714286 0.857143
0.428571 0.714286 1.0
0.428571 0.857143 0.0
0.428571 0.857143 0.142857
0.428571 0.857143 0.285714
0.428571 0.857143 0.428571
0.428571 0.857143 0.571429
0.428571 0.857143 0.714286
0.428571 0.857143 0.857143
0.428571 0.857143 1.0
0.428571 1.0 0.0
0.428571 1.0 0.142857
0.428571 1.0 0.285714
0.428571 1.0 0.428571
0.428571 1.0 0.571429
0.428571 1.0 0.714286
0.428571 1.0 0.857143
0.428571 1.0 1.0
0.571429 0.0 0.0
0.571429 0.0 0.142857
0.571429 0.0 0.285714
0.571429 0.0 0.428571
0.571429 0.0 0.571429
0.571429 0.0 0.714286
0.571429 0.0 0.857143
0.571429 0.0 1.0
0.571429 0.142857 0.0
0.571429 0.142857 0.142857
0.571429 0.142857 0.285714
0.571429 0.142857 0.428571
0.571429 0.142857 0.571429
0.571429 0.142857 0.714286
0.571429 0.142857 0.857143
0.571429 0.142857 1.0
0.571429 0.285714 0.0
0.571429 0.285714 0.142857
0.571429 0.285714 0.285714
0.571429 0.285714 0.428571
0.571429 0.285714 0.571429
0.571429 0.285714 0.714286
0.571429 0.285714 0.857143
0.571429 0.285714 1.0
0.571429 0.428571 0.0
0.571429 0.428571 0.142857
0.571429 0.428571 0.285714
0.571429 0.428571 0.428571
0.571429 0.428571 0.571429
0.571429 0.428571 0.714286
0.571429 0.428571 0.857143
0.571429 0.428571 1.0
0.571429 0.571429 0.0
0.571429 0.571429 0.142857
0.571429 0.571429 0.285714
0.571429 0.571429 0.428571
0.571429 0.571429 0.571429
0.571429 0.571429 0.714286
0.571429 0.571429 0.857143
0.571429 0.571429 1.0
0.571429 0.714286 0.0
0.571429 0.714286 0.142857
0.571429 0.714286 0.285714
0.571429 0.714286 0.428571
0.571429 0.714286 0.571429
0.571429 0.714286 0.714286
0.571429 0.714286 0.857143
0.571429 0.714286 1.0
0.571429 0.857143 0.0
0.571429 0.857143 0.142857
0.571429 0.857143 0.285714
0.571429 0.857143 0.428571
0.571429 0.857143 0.571429
0.571429 0.857143 0.714286
0.571429 0.857143 0.857143
0.571429 0.857143 1.0
0.571429 1.0 0.0
0.571429 1.0 0.142857
0.571429 1.0 0.285714
0.571429 1.0 0.428571
0.571429 1.0 0.571429
0.571429 1.0 0.714286
0.571429 1.0 0.857143
0.571429 1.0 1.0
0.714286 0.0 0.0
0.714286 0.0 0.142857
0.714286 0.0 0.285714
0.714286 0.0 0.428571
0.714286 0.0 0.571429
0.714286 0.0 0.714286
0.714286 0.0 0.857143
0.714286 0.0 1.0
0.714286 0.142857 0.0
0.714286 0.142857 0.142857
0.714286 0.142857 0.285714
0.714286 0.142857 0.428571
0.714286 0.142857 0.571429
0.714286 0.142857 0.714286
0.714286 0.142857 0.857143
0.714286 0.142857 1.0
0.714286 0.285714 0.0
0.714286 0.285714 0.142857
0.714286 0.285714 0.285714
0.714286 0.285714 0.428571
0.714286 0.285714 0.571429
0.714286 0.285714 0.714286
0.714286 0.285714 0.857143
0.714286 0.285714 1.0
0.714286 0.428571 0.0
0.714286 0.428571 0.142857
0.714286 0.428571 0.285714
0.714286 0.428571 0.428571
0.714286 0.428571 0.571429
0.714286 0.428571 0.714286
0.714286 0.428571 0.857143
0.714286 0.428571 1.0
0.714286 0.571429 0.0
0.714286 0.571429 0.142857
0.714286 0.571429 0.285714
0.714286 0.571429 0.428571
0.714286 0.571429 0.571429
0.714286 0.571429 0.714286
0.714286 0.571429 0.857143
0.714286 0.571429 1.0
0.714286 0.714286 0.0
0.714286 0.714286 0.142857
0.714286 0.714286 0.285714
0.714286 0.714286 0.428571
0.714286 0.714286 0.571429
0.714286 0.714286 0.714286
0.714286 0.714286 0.857143
0.714286 0.714286 1.0
0.714286 0.857143 0.0
0.714286 0.857143 0.142857
0.714286 0.857143 0.285714
0.714286 0.857143 0.428571
0.714286 0.857143 0.571429
0.714286 0.857143 0.714286
0.714286 0.857143 0.857143
0.714286 0.857143 1.0
0.714286 1.0 0.0
0.714286 1.0 0.142857
0.714286 1.0 0.285714
0.714286 1.0 0.428571
0.714286 1.0 0.571429
0.714286 1.0 0.714286
0.714286 1.0 0.857143
0.714286 1.0 1.0
0.857143 0.0 0.0
0.857143 0.0 0.142857
0.857143 0.0 0.285714
0.857143 0.0 0.428571
0.857143 0.0 0.571429
0.857143 0.0 0.714286
0.857143 0.0 0.857143
0.857143 0.0 1.0
0.857143 0.142857 0.0
0.857143 0.142857 0.142857
0.857143 0.142857 0.285714
0.857143 0.142857 0.428571
0.857143 0.142857 0.571429
0.857143 0.142857 0.714286
0.857143 0.142857 0.857143
0.857143 0.142857 1.0
0.857143 0.285714 0.0
0.857143 0.285714 0.142857
0.857143 0.285714 0.285714
0.857143 0.285714 0.428571
0.857143 0.285714 0.571429
0.857143 0.285714 0.714286
0.857143 0.285714 0.857143
0.857143 0.285714 1.0
0.857143 0.428571 0.0
0.857143 0.428571 0.142857
0.857143 0.428571 0.285714
0.857143 0.428571 0.428571
0.857143 0.428571 0.571429
0.857143 0.428571 0.714286
0.857143 0.428571 0.857143
0.857143 0.428571 1.0
0.857143 0.571429 0.0
0.857143 0.571429 0.142857
0.857143 0.571429 0.285714
0.857143 0.571429 0.428571
0.857143 0.571429 0.571429
0.857143 0.571429 0.714286
0.857143 0.571429 0.857143
0.857143 0.571429 1.0
0.857143 0.714286 0.0
0.857143 0.714286 0.142857
0.857143 0.714286 0.285714
0.857143 0.714286 0.428571
0.857143 0.714286 0.571429
0.857143 0.714286 0.714286
0.857143 0.714286 0.857143
0.857143 0.714286 1.0
0.857143 0.857143 0.0
0.857143 0.857143 0.142857
0.857143 0.857143 0.285714
0.857143 0.857143 0.428571
0.857143 0.857143 0.571429
0.857143 0.857143 0.714286
0.857143 0.857143 0.857143
0.857143 0.857143 1.0
0.857143 1.0 0.0
0.857143 1.0 0.142857
0.857143 1.0 0.285714
0.857143 1.0 0.428571
0.857143 1.0 0.571429
0.857143 1.0 0.714286
0.857143 1.0 0.857143
0.857143 1.0 1.0
1.0 0.0 0.0
1.0 0.0 0.142857
1.0 0.0 0.285714
1.0 0.0 0.428571
1.0 0.0 0.571429
1.0 0.0 0.714286
1.0 0.0 0.857143
1.0 0.0 1.0
1.0 0.142857 0.0
1.0 0.142857 0.142857
1.0 0.142857 0.285714
1.0 0.142857 0.428571
1.0 0.142857 0.571429
1.0 0.142857 0.714286
1.0 0.142857 0.857143
1.0 0.142857 1.0
1.0 0.285714 0.0
1.0 0.285714 0.142857
1.0 0.285714 0.285714
1.0 0.285714 0.428571
1.0 0.285714 0.571429
1.0 0.285714 0.714286
1.0 0.285714 0.857143
1.0 0.285714 1.0
1.0 0.428571 0.0
1.0 0.428571 0.142857
1.0 0.428571 0.285714
1.0 0.428571 0.428571
1.0 0.428571 0.571429
1.0 0.428571 0.714286
1.0 0.428571 0.857143
1.0 0.428571 1.0
1.0 0.571429 0.0
1.0 0.571429 0.142857
1.0 0.571429 0.285714
1.0 0.571429 0.428571
1.0 0.571429 0.571429
1.0 0.571429 0.714286
1.0 0.571429 0.857143
1.0 0.571429 1.0
1.0 0.714286 0.0
1.0 0.714286 0.142857
1.0 0.714286 0.285714
1.0 0.714286 0.428571
1.0 0.714286 0.571429
1.0 0.714286 0.714286
1.0 0.714286 0.857143
1.0 0.714286 1.0
1.0 0.857143 0.0
1.0 0.857143 0.142857
1.0 0.857143 0.285714
1.0 0.857143 0.428571
1.0 0.857143 0.571429
1.0 0.857143 0.714286
1.0 0.857143 0.857143
1.0 0.857143 1.0
1.0 1.0 0.0
1.0 1.0 0.142857
1.0 1.0 0.285714
1.0 1.0 0.428571
1.0 1.0 0.571429
1.0 1.0 0.714286
1.0 1.0 0.857143
1.0 1.0 1.0

================
File: camera/cameraApp.swift
================
//
//  cameraApp.swift
//  camera
//
//  Created by spencer on 2024-12-22.
//

import SwiftUI

@main
struct cameraApp: App {
    let persistenceController = PersistenceController.shared

    var body: some Scene {
        WindowGroup {
            ContentView()
                .environment(\.managedObjectContext, persistenceController.container.viewContext)
        }
    }
}

================
File: camera/ContentView.swift
================
import SwiftUI
import CoreData
import CoreMedia

struct ContentView: View {
    @StateObject private var viewModel = CameraViewModel()
    @State private var orientation = UIDevice.current.orientation
    @StateObject private var lutManager = LUTManager()
    @State private var isShowingSettings = false
    @State private var isShowingDocumentPicker = false
    
    var body: some View {
        GeometryReader { geometry in
            ZStack {
                if viewModel.isSessionRunning {
                    CameraPreviewView(
                        session: viewModel.session,
                        lutManager: lutManager,
                        viewModel: viewModel
                    )
                    .ignoresSafeArea()
                    .frame(width: geometry.size.width,
                           height: geometry.size.height)
                    
                    VStack {
                        Spacer()
                        controlsView
                            .frame(maxWidth: geometry.size.width * 0.9)
                            .padding(.bottom, 30)
                    }
                } else {
                    // Loading indicator while camera session initializes
                    ProgressView("Initializing Camera...")
                        .frame(maxWidth: .infinity, maxHeight: .infinity)
                        .background(Color.black.opacity(0.7))
                }
            }
            .edgesIgnoringSafeArea(.all)
            .onRotate { newOrientation in
                orientation = newOrientation
            }
        }
        .onAppear {
            viewModel.updateInterfaceOrientation()
        }
        .onChange(of: UIDevice.current.orientation) { oldValue, newValue in
            viewModel.updateInterfaceOrientation()
        }
        .alert(item: $viewModel.error) { error in
            Alert(title: Text("Error"),
                  message: Text(error.description),
                  dismissButton: .default(Text("OK")))
        }
        .sheet(isPresented: $isShowingSettings) {
            SettingsView(lutManager: lutManager)
        }
        .sheet(isPresented: $isShowingDocumentPicker) {
            DocumentPicker(types: LUTManager.supportedTypes) { url in
                // Use main thread for UI updates
                DispatchQueue.main.async {
                    handleLUTImport(url: url)
                    isShowingDocumentPicker = false
                }
            }
        }
    }
    
    // Camera controls
    private var controlsView: some View {
        VStack(spacing: 15) {
            Text("Camera Controls")
                .font(.headline)
            
            // Frame Rate Picker
            HStack {
                Text("FPS:")
                Picker("Frame Rate", selection: $viewModel.selectedFrameRate) {
                    ForEach(viewModel.availableFrameRates, id: \.self) { fps in
                        Text(
                            fps == 29.97 ? "29.97" : 
                            fps == 23.976 ? "23.98" : 
                            String(format: "%.0f", fps)
                        )
                        .tag(fps)
                    }
                }
                .pickerStyle(.menu)
                .onChange(of: viewModel.selectedFrameRate) { oldValue, newValue in
                    viewModel.updateFrameRate(newValue)
                }
            }
            
            // White Balance
            HStack {
                Text("WB: \(Int(viewModel.whiteBalance))K")
                Slider(value: $viewModel.whiteBalance,
                       in: 2000...8000,
                       step: 100) { _ in
                    viewModel.updateWhiteBalance(viewModel.whiteBalance)
                }
            }
            
            // Tint Control
            HStack {
                Text("Tint: \(Int(viewModel.currentTint))")
                Slider(
                    value: $viewModel.currentTint,
                    in: -150...150,
                    step: 1
                ) { _ in
                    viewModel.updateTint(viewModel.currentTint)
                }
                .tint(.green)
            }
            
            // ISO
            HStack {
                Text("ISO: \(Int(viewModel.iso))")
                Slider(value: $viewModel.iso,
                       in: viewModel.minISO...viewModel.maxISO,
                       step: 1) { _ in
                    viewModel.updateISO(viewModel.iso)
                }
            }
            .disabled(viewModel.isAutoExposureEnabled)
            .opacity(viewModel.isAutoExposureEnabled ? 0.6 : 1.0)
            
            // Shutter
            HStack {
                let currentAngle = viewModel.shutterAngle
                Text("Shutter: \(Int(currentAngle))¬∞ (\(ShutterAngle(rawValue: currentAngle)?.shutterSpeed ?? "Custom"))")
                
                Picker("Shutter Angle", selection: Binding(
                    get: {
                        // Find the closest standard angle
                        ShutterAngle.allCases.min(by: { abs($0.rawValue - viewModel.shutterAngle) < abs($1.rawValue - viewModel.shutterAngle) })?.rawValue ?? 180.0
                    },
                    set: { newValue in
                        print("\nüéöÔ∏è Shutter Angle Changed:")
                        print("  - New Value: \(newValue)¬∞")
                        viewModel.updateShutterAngle(newValue)
                    }
                )) {
                    ForEach(ShutterAngle.allCases, id: \.rawValue) { angle in
                        Text("\(Int(angle.rawValue))¬∞ (\(angle.shutterSpeed))")
                            .tag(angle.rawValue)
                    }
                }
                .pickerStyle(.menu)
            }
            .disabled(viewModel.isAutoExposureEnabled)
            .opacity(viewModel.isAutoExposureEnabled ? 0.6 : 1.0)
            
            // LUT Controls
            VStack(spacing: 8) {
                HStack {
                    Text("LUT Preview")
                    Spacer()
                    if lutManager.currentLUTFilter != nil {
                        Image(systemName: "checkmark.circle.fill")
                            .foregroundColor(.green)
                    }
                    Toggle("", isOn: Binding(
                        get: { lutManager.currentLUTFilter != nil },
                        set: { enabled in
                            if !enabled {
                                lutManager.clearLUT()
                            } else if let url = lutManager.selectedLUTURL {
                                lutManager.loadLUT(from: url)
                            } else {
                                isShowingDocumentPicker = true
                            }
                        }
                    ))
                    .labelsHidden()
                }
                .tint(.green)
                
                if let lutName = lutManager.selectedLUTURL?.lastPathComponent {
                    HStack {
                        Text(lutName)
                            .font(.caption)
                            .foregroundColor(.secondary)
                        Spacer()
                        Button(action: {
                            lutManager.clearLUT()
                        }) {
                            Image(systemName: "xmark.circle.fill")
                                .foregroundColor(.red)
                        }
                    }
                }
                
                Button(action: {
                    isShowingDocumentPicker = true
                }) {
                    HStack {
                        Image(systemName: "photo.fill")
                        Text("Import LUT")
                    }
                    .frame(maxWidth: .infinity)
                    .padding(.vertical, 8)
                }
                .buttonStyle(.bordered)
                .tint(.blue)
            }
            .padding(.vertical, 4)

            // Auto Exposure toggle
            Toggle(isOn: $viewModel.isAutoExposureEnabled) {
                HStack {
                    Text("Auto Exposure")
                    if viewModel.isAutoExposureEnabled {
                        Image(systemName: "a.circle.fill")
                            .foregroundColor(.green)
                    } else {
                        Image(systemName: "m.circle.fill")
                            .foregroundColor(.orange)
                    }
                }
            }
            .tint(.green)
            
            // Apple Log toggle if supported
            if viewModel.isAppleLogSupported {
                Toggle(isOn: $viewModel.isAppleLogEnabled) {
                    HStack {
                        Text("Enable LOG")
                        if viewModel.isAppleLogEnabled {
                            Image(systemName: "checkmark.circle.fill")
                                .foregroundColor(.green)
                        }
                    }
                }
                .tint(.green)
            }
            
            // Record button
            Button(action: {
                if viewModel.isRecording {
                    viewModel.stopRecording()
                } else {
                    viewModel.startRecording()
                }
            }) {
                Image(systemName: viewModel.isRecording ? "stop.circle" : "record.circle")
                    .font(.system(size: 60))
                    .foregroundColor(viewModel.isRecording ? .white : .red)
                    .opacity(viewModel.isProcessingRecording ? 0.5 : 1.0)
            }
            .disabled(viewModel.isProcessingRecording)
        }
        .padding()
        .background(Color.black.opacity(0.6))
        .cornerRadius(15)
        .foregroundColor(.white)
    }
    
    // MARK: - LUT File Handling
    private func handleLUTImport(url: URL) {
        print("\nüì± ContentView: Handling LUT import from: \(url.path)")
        
        // Add a longer delay to ensure the UI has fully updated before performing file operations
        // This helps prevent view service termination errors
        DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
            do {
                // Check if file exists and is accessible
                guard FileManager.default.fileExists(atPath: url.path) else {
                    print("‚ùå ContentView: LUT file does not exist at path: \(url.path)")
                    return
                }
                
                // Get file attributes
                let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
                if let fileSize = attributes[.size] as? NSNumber {
                    print("üì± ContentView: LUT file size: \(fileSize.intValue) bytes")
                    
                    // Warn if file is suspiciously small
                    if fileSize.intValue < 100 {
                        print("‚ö†Ô∏è ContentView: LUT file seems unusually small (\(fileSize.intValue) bytes)")
                    }
                }
                
                // Directly pass the URL to LUTManager, which now handles the file properly
                // without trying to create additional copies
                self.lutManager.loadLUT(from: url)
                
            } catch {
                print("‚ùå ContentView: Error handling LUT file: \(error.localizedDescription)")
                if let nsError = error as NSError? {
                    print("‚ùå ContentView: Error domain: \(nsError.domain), code: \(nsError.code)")
                    if let underlyingError = nsError.userInfo[NSUnderlyingErrorKey] as? NSError {
                        print("‚ùå ContentView: Underlying error: \(underlyingError.localizedDescription)")
                    }
                }
            }
        }
    }
}

// A rotation view modifier to track device orientation changes
struct DeviceRotationViewModifier: ViewModifier {
    let action: (UIDeviceOrientation) -> Void
    
    func body(content: Content) -> some View {
        content
            .onAppear()
            .onReceive(NotificationCenter.default.publisher(for: UIDevice.orientationDidChangeNotification)) { _ in
                action(UIDevice.current.orientation)
            }
    }
}

extension View {
    func onRotate(perform action: @escaping (UIDeviceOrientation) -> Void) -> some View {
        self.modifier(DeviceRotationViewModifier(action: action))
    }
}

================
File: camera/Info.plist
================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>UIApplicationSceneManifest</key>
	<dict>
		<key>UIApplicationSupportsMultipleScenes</key>
		<false/>
	</dict>
	<key>NSCameraUsageDescription</key>
	<string>This app needs camera access to record video</string>
	<key>NSMicrophoneUsageDescription</key>
	<string>This app needs microphone access to record audio</string>
	<key>LSSupportsOpeningDocumentsInPlace</key>
	<true/>
	<key>UIFileSharingEnabled</key>
	<true/>
</dict>
</plist>

================
File: camera/Persistence.swift
================
//
//  Persistence.swift
//  camera
//
//  Created by spencer on 2024-12-22.
//

import CoreData

struct PersistenceController {
    static let shared = PersistenceController()

    @MainActor
    static let preview: PersistenceController = {
        let result = PersistenceController(inMemory: true)
        let viewContext = result.container.viewContext
        for _ in 0..<10 {
            let newItem = Item(context: viewContext)
            newItem.timestamp = Date()
        }
        do {
            try viewContext.save()
        } catch {
            // Replace this implementation with code to handle the error appropriately.
            // fatalError() causes the application to generate a crash log and terminate. You should not use this function in a shipping application, although it may be useful during development.
            let nsError = error as NSError
            fatalError("Unresolved error \(nsError), \(nsError.userInfo)")
        }
        return result
    }()

    let container: NSPersistentContainer

    init(inMemory: Bool = false) {
        container = NSPersistentContainer(name: "camera")
        if inMemory {
            container.persistentStoreDescriptions.first!.url = URL(fileURLWithPath: "/dev/null")
        }
        container.loadPersistentStores(completionHandler: { (storeDescription, error) in
            if let error = error as NSError? {
                // Replace this implementation with code to handle the error appropriately.
                // fatalError() causes the application to generate a crash log and terminate. You should not use this function in a shipping application, although it may be useful during development.

                /*
                 Typical reasons for an error here include:
                 * The parent directory does not exist, cannot be created, or disallows writing.
                 * The persistent store is not accessible, due to permissions or data protection when the device is locked.
                 * The device is out of space.
                 * The store could not be migrated to the current model version.
                 Check the error message to determine what the actual problem was.
                 */
                fatalError("Unresolved error \(error), \(error.userInfo)")
            }
        })
        container.viewContext.automaticallyMergesChangesFromParent = true
    }
}

================
File: camera.xcodeproj/project.xcworkspace/contents.xcworkspacedata
================
<?xml version="1.0" encoding="UTF-8"?>
<Workspace
   version = "1.0">
   <FileRef
      location = "self:">
   </FileRef>
</Workspace>

================
File: camera.xcodeproj/xcuserdata/spencer.xcuserdatad/xcdebugger/Breakpoints_v2.xcbkptlist
================
<?xml version="1.0" encoding="UTF-8"?>
<Bucket
   uuid = "8C0EC471-D08D-4370-AFA9-6904E3CF5246"
   type = "1"
   version = "2.0">
</Bucket>

================
File: camera.xcodeproj/xcuserdata/spencer.xcuserdatad/xcschemes/xcschememanagement.plist
================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>SchemeUserState</key>
	<dict>
		<key>camera.xcscheme_^#shared#^_</key>
		<dict>
			<key>orderHint</key>
			<integer>0</integer>
		</dict>
	</dict>
</dict>
</plist>

================
File: camera.xcodeproj/project.pbxproj
================
// !$*UTF8*$!
{
	archiveVersion = 1;
	classes = {
	};
	objectVersion = 77;
	objects = {

/* Begin PBXFileReference section */
		09562D7C2D18A1EC009A9B07 /* camera.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = camera.app; sourceTree = BUILT_PRODUCTS_DIR; };
/* End PBXFileReference section */

/* Begin PBXFileSystemSynchronizedBuildFileExceptionSet section */
		09562DB12D18A28C009A9B07 /* Exceptions for "camera" folder in "camera" target */ = {
			isa = PBXFileSystemSynchronizedBuildFileExceptionSet;
			membershipExceptions = (
				Info.plist,
			);
			target = 09562D7B2D18A1EC009A9B07 /* camera */;
		};
/* End PBXFileSystemSynchronizedBuildFileExceptionSet section */

/* Begin PBXFileSystemSynchronizedRootGroup section */
		09562D7E2D18A1EC009A9B07 /* camera */ = {
			isa = PBXFileSystemSynchronizedRootGroup;
			exceptions = (
				09562DB12D18A28C009A9B07 /* Exceptions for "camera" folder in "camera" target */,
			);
			path = camera;
			sourceTree = "<group>";
		};
/* End PBXFileSystemSynchronizedRootGroup section */

/* Begin PBXFrameworksBuildPhase section */
		09562D792D18A1EC009A9B07 /* Frameworks */ = {
			isa = PBXFrameworksBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXFrameworksBuildPhase section */

/* Begin PBXGroup section */
		09562D732D18A1EC009A9B07 = {
			isa = PBXGroup;
			children = (
				09562D7E2D18A1EC009A9B07 /* camera */,
				09562D7D2D18A1EC009A9B07 /* Products */,
			);
			sourceTree = "<group>";
		};
		09562D7D2D18A1EC009A9B07 /* Products */ = {
			isa = PBXGroup;
			children = (
				09562D7C2D18A1EC009A9B07 /* camera.app */,
			);
			name = Products;
			sourceTree = "<group>";
		};
/* End PBXGroup section */

/* Begin PBXNativeTarget section */
		09562D7B2D18A1EC009A9B07 /* camera */ = {
			isa = PBXNativeTarget;
			buildConfigurationList = 09562D8F2D18A1EE009A9B07 /* Build configuration list for PBXNativeTarget "camera" */;
			buildPhases = (
				09562D782D18A1EC009A9B07 /* Sources */,
				09562D792D18A1EC009A9B07 /* Frameworks */,
				09562D7A2D18A1EC009A9B07 /* Resources */,
			);
			buildRules = (
			);
			dependencies = (
			);
			fileSystemSynchronizedGroups = (
				09562D7E2D18A1EC009A9B07 /* camera */,
			);
			name = camera;
			packageProductDependencies = (
			);
			productName = camera;
			productReference = 09562D7C2D18A1EC009A9B07 /* camera.app */;
			productType = "com.apple.product-type.application";
		};
/* End PBXNativeTarget section */

/* Begin PBXProject section */
		09562D742D18A1EC009A9B07 /* Project object */ = {
			isa = PBXProject;
			attributes = {
				BuildIndependentTargetsInParallel = 1;
				LastSwiftUpdateCheck = 1620;
				LastUpgradeCheck = 1620;
				TargetAttributes = {
					09562D7B2D18A1EC009A9B07 = {
						CreatedOnToolsVersion = 16.2;
					};
				};
			};
			buildConfigurationList = 09562D772D18A1EC009A9B07 /* Build configuration list for PBXProject "camera" */;
			developmentRegion = en;
			hasScannedForEncodings = 0;
			knownRegions = (
				en,
				Base,
			);
			mainGroup = 09562D732D18A1EC009A9B07;
			minimizedProjectReferenceProxies = 1;
			preferredProjectObjectVersion = 77;
			productRefGroup = 09562D7D2D18A1EC009A9B07 /* Products */;
			projectDirPath = "";
			projectRoot = "";
			targets = (
				09562D7B2D18A1EC009A9B07 /* camera */,
			);
		};
/* End PBXProject section */

/* Begin PBXResourcesBuildPhase section */
		09562D7A2D18A1EC009A9B07 /* Resources */ = {
			isa = PBXResourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXResourcesBuildPhase section */

/* Begin PBXSourcesBuildPhase section */
		09562D782D18A1EC009A9B07 /* Sources */ = {
			isa = PBXSourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXSourcesBuildPhase section */

/* Begin XCBuildConfiguration section */
		09562D8D2D18A1EE009A9B07 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				ASSETCATALOG_COMPILER_GENERATE_SWIFT_ASSET_SYMBOL_EXTENSIONS = YES;
				CLANG_ANALYZER_NONNULL = YES;
				CLANG_ANALYZER_NUMBER_OBJECT_CONVERSION = YES_AGGRESSIVE;
				CLANG_CXX_LANGUAGE_STANDARD = "gnu++20";
				CLANG_ENABLE_MODULES = YES;
				CLANG_ENABLE_OBJC_ARC = YES;
				CLANG_ENABLE_OBJC_WEAK = YES;
				CLANG_WARN_BLOCK_CAPTURE_AUTORELEASING = YES;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_COMMA = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_DEPRECATED_OBJC_IMPLEMENTATIONS = YES;
				CLANG_WARN_DIRECT_OBJC_ISA_USAGE = YES_ERROR;
				CLANG_WARN_DOCUMENTATION_COMMENTS = YES;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INFINITE_RECURSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN_NON_LITERAL_NULL_CONVERSION = YES;
				CLANG_WARN_OBJC_IMPLICIT_RETAIN_SELF = YES;
				CLANG_WARN_OBJC_LITERAL_CONVERSION = YES;
				CLANG_WARN_OBJC_ROOT_CLASS = YES_ERROR;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = YES;
				CLANG_WARN_RANGE_LOOP_ANALYSIS = YES;
				CLANG_WARN_STRICT_PROTOTYPES = YES;
				CLANG_WARN_SUSPICIOUS_MOVE = YES;
				CLANG_WARN_UNGUARDED_AVAILABILITY = YES_AGGRESSIVE;
				CLANG_WARN_UNREACHABLE_CODE = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				COPY_PHASE_STRIP = NO;
				DEBUG_INFORMATION_FORMAT = dwarf;
				ENABLE_STRICT_OBJC_MSGSEND = YES;
				ENABLE_TESTABILITY = YES;
				ENABLE_USER_SCRIPT_SANDBOXING = YES;
				GCC_C_LANGUAGE_STANDARD = gnu17;
				GCC_DYNAMIC_NO_PIC = NO;
				GCC_NO_COMMON_BLOCKS = YES;
				GCC_OPTIMIZATION_LEVEL = 0;
				GCC_PREPROCESSOR_DEFINITIONS = (
					"DEBUG=1",
					"$(inherited)",
				);
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES_ERROR;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				IPHONEOS_DEPLOYMENT_TARGET = 18.2;
				LOCALIZATION_PREFERS_STRING_CATALOGS = YES;
				MTL_ENABLE_DEBUG_INFO = INCLUDE_SOURCE;
				MTL_FAST_MATH = YES;
				ONLY_ACTIVE_ARCH = YES;
				SDKROOT = iphoneos;
				SWIFT_ACTIVE_COMPILATION_CONDITIONS = "DEBUG $(inherited)";
				SWIFT_OPTIMIZATION_LEVEL = "-Onone";
			};
			name = Debug;
		};
		09562D8E2D18A1EE009A9B07 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				ASSETCATALOG_COMPILER_GENERATE_SWIFT_ASSET_SYMBOL_EXTENSIONS = YES;
				CLANG_ANALYZER_NONNULL = YES;
				CLANG_ANALYZER_NUMBER_OBJECT_CONVERSION = YES_AGGRESSIVE;
				CLANG_CXX_LANGUAGE_STANDARD = "gnu++20";
				CLANG_ENABLE_MODULES = YES;
				CLANG_ENABLE_OBJC_ARC = YES;
				CLANG_ENABLE_OBJC_WEAK = YES;
				CLANG_WARN_BLOCK_CAPTURE_AUTORELEASING = YES;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_COMMA = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_DEPRECATED_OBJC_IMPLEMENTATIONS = YES;
				CLANG_WARN_DIRECT_OBJC_ISA_USAGE = YES_ERROR;
				CLANG_WARN_DOCUMENTATION_COMMENTS = YES;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INFINITE_RECURSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN_NON_LITERAL_NULL_CONVERSION = YES;
				CLANG_WARN_OBJC_IMPLICIT_RETAIN_SELF = YES;
				CLANG_WARN_OBJC_LITERAL_CONVERSION = YES;
				CLANG_WARN_OBJC_ROOT_CLASS = YES_ERROR;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = YES;
				CLANG_WARN_RANGE_LOOP_ANALYSIS = YES;
				CLANG_WARN_STRICT_PROTOTYPES = YES;
				CLANG_WARN_SUSPICIOUS_MOVE = YES;
				CLANG_WARN_UNGUARDED_AVAILABILITY = YES_AGGRESSIVE;
				CLANG_WARN_UNREACHABLE_CODE = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				COPY_PHASE_STRIP = NO;
				DEBUG_INFORMATION_FORMAT = "dwarf-with-dsym";
				ENABLE_NS_ASSERTIONS = NO;
				ENABLE_STRICT_OBJC_MSGSEND = YES;
				ENABLE_USER_SCRIPT_SANDBOXING = YES;
				GCC_C_LANGUAGE_STANDARD = gnu17;
				GCC_NO_COMMON_BLOCKS = YES;
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES_ERROR;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				IPHONEOS_DEPLOYMENT_TARGET = 18.2;
				LOCALIZATION_PREFERS_STRING_CATALOGS = YES;
				MTL_ENABLE_DEBUG_INFO = NO;
				MTL_FAST_MATH = YES;
				SDKROOT = iphoneos;
				SWIFT_COMPILATION_MODE = wholemodule;
				VALIDATE_PRODUCT = YES;
			};
			name = Release;
		};
		09562D902D18A1EE009A9B07 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;
				ASSETCATALOG_COMPILER_GLOBAL_ACCENT_COLOR_NAME = AccentColor;
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 1;
				DEVELOPMENT_ASSET_PATHS = "\"camera/Preview Content\"";
				DEVELOPMENT_TEAM = 3B883XKLK8;
				ENABLE_PREVIEWS = YES;
				GENERATE_INFOPLIST_FILE = YES;
				INFOPLIST_FILE = camera/Info.plist;
				INFOPLIST_KEY_NSCameraUsageDescription = "This app needs camera access to record video";
				INFOPLIST_KEY_NSMicrophoneUsageDescription = "This app needs microphone access to record audio";
				INFOPLIST_KEY_NSPhotoLibraryAddUsageDescription = "This app needs access to save recorded videos";
				INFOPLIST_KEY_NSPhotoLibraryUsageDescription = "This app needs access to save recorded videos";
				INFOPLIST_KEY_UIApplicationSupportsIndirectInputEvents = YES;
				INFOPLIST_KEY_UILaunchScreen_Generation = YES;
				INFOPLIST_KEY_UISupportedInterfaceOrientations = "UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight UIInterfaceOrientationPortrait";
				INFOPLIST_KEY_UISupportedInterfaceOrientations_iPad = "UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight UIInterfaceOrientationPortrait UIInterfaceOrientationPortraitUpsideDown";
				LD_RUNPATH_SEARCH_PATHS = (
					"$(inherited)",
					"@executable_path/Frameworks",
				);
				MARKETING_VERSION = 1.0;
				PRODUCT_BUNDLE_IDENTIFIER = com.spencershwetz.camera;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SUPPORTED_PLATFORMS = "iphoneos iphonesimulator";
				SUPPORTS_MACCATALYST = NO;
				SUPPORTS_MAC_DESIGNED_FOR_IPHONE_IPAD = NO;
				SUPPORTS_XR_DESIGNED_FOR_IPHONE_IPAD = NO;
				SWIFT_EMIT_LOC_STRINGS = YES;
				SWIFT_VERSION = 5.0;
				TARGETED_DEVICE_FAMILY = "1,2";
			};
			name = Debug;
		};
		09562D912D18A1EE009A9B07 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;
				ASSETCATALOG_COMPILER_GLOBAL_ACCENT_COLOR_NAME = AccentColor;
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 1;
				DEVELOPMENT_ASSET_PATHS = "\"camera/Preview Content\"";
				DEVELOPMENT_TEAM = 3B883XKLK8;
				ENABLE_PREVIEWS = YES;
				GENERATE_INFOPLIST_FILE = YES;
				INFOPLIST_FILE = camera/Info.plist;
				INFOPLIST_KEY_NSCameraUsageDescription = "This app needs camera access to record video";
				INFOPLIST_KEY_NSMicrophoneUsageDescription = "This app needs microphone access to record audio";
				INFOPLIST_KEY_NSPhotoLibraryAddUsageDescription = "This app needs access to save recorded videos";
				INFOPLIST_KEY_NSPhotoLibraryUsageDescription = "This app needs access to save recorded videos";
				INFOPLIST_KEY_UIApplicationSupportsIndirectInputEvents = YES;
				INFOPLIST_KEY_UILaunchScreen_Generation = YES;
				INFOPLIST_KEY_UISupportedInterfaceOrientations = "UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight UIInterfaceOrientationPortrait";
				INFOPLIST_KEY_UISupportedInterfaceOrientations_iPad = "UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight UIInterfaceOrientationPortrait UIInterfaceOrientationPortraitUpsideDown";
				LD_RUNPATH_SEARCH_PATHS = (
					"$(inherited)",
					"@executable_path/Frameworks",
				);
				MARKETING_VERSION = 1.0;
				PRODUCT_BUNDLE_IDENTIFIER = com.spencershwetz.camera;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SUPPORTED_PLATFORMS = "iphoneos iphonesimulator";
				SUPPORTS_MACCATALYST = NO;
				SUPPORTS_MAC_DESIGNED_FOR_IPHONE_IPAD = NO;
				SUPPORTS_XR_DESIGNED_FOR_IPHONE_IPAD = NO;
				SWIFT_EMIT_LOC_STRINGS = YES;
				SWIFT_VERSION = 5.0;
				TARGETED_DEVICE_FAMILY = "1,2";
			};
			name = Release;
		};
/* End XCBuildConfiguration section */

/* Begin XCConfigurationList section */
		09562D772D18A1EC009A9B07 /* Build configuration list for PBXProject "camera" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				09562D8D2D18A1EE009A9B07 /* Debug */,
				09562D8E2D18A1EE009A9B07 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		09562D8F2D18A1EE009A9B07 /* Build configuration list for PBXNativeTarget "camera" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				09562D902D18A1EE009A9B07 /* Debug */,
				09562D912D18A1EE009A9B07 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
/* End XCConfigurationList section */
	};
	rootObject = 09562D742D18A1EC009A9B07 /* Project object */;
}
